{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankNote=pd.read_csv('banknote.csv')\n",
    "car=pd.read_csv('car.csv')\n",
    "bankNote=shuffle(bankNote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Centroid</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Rolloff</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Flux</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_0</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_1</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_2</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_3</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_4</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_5</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_6</th>\n",
       "      <th>...</th>\n",
       "      <th>BH_HighLowRatio</th>\n",
       "      <th>BHSUM1</th>\n",
       "      <th>BHSUM2</th>\n",
       "      <th>BHSUM3</th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034741</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.091225</td>\n",
       "      <td>-73.302422</td>\n",
       "      <td>6.215179</td>\n",
       "      <td>0.615074</td>\n",
       "      <td>2.037160</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>1.301409</td>\n",
       "      <td>0.558576</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.245457</td>\n",
       "      <td>0.105065</td>\n",
       "      <td>0.405399</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081374</td>\n",
       "      <td>0.272747</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>-62.584437</td>\n",
       "      <td>3.183163</td>\n",
       "      <td>-0.218145</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.343547</td>\n",
       "      <td>0.276366</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110545</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>0.084410</td>\n",
       "      <td>-65.235325</td>\n",
       "      <td>2.794964</td>\n",
       "      <td>0.639047</td>\n",
       "      <td>1.281297</td>\n",
       "      <td>0.757896</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.627636</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.188693</td>\n",
       "      <td>0.045941</td>\n",
       "      <td>0.457372</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>-80.305152</td>\n",
       "      <td>5.824409</td>\n",
       "      <td>0.648848</td>\n",
       "      <td>1.754870</td>\n",
       "      <td>1.495532</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.809644</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102839</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>0.351009</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.140880</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>-93.697749</td>\n",
       "      <td>5.543229</td>\n",
       "      <td>1.064262</td>\n",
       "      <td>0.899152</td>\n",
       "      <td>0.890336</td>\n",
       "      <td>0.702328</td>\n",
       "      <td>0.490685</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.195196</td>\n",
       "      <td>0.310801</td>\n",
       "      <td>0.683817</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Acc1298_Mean_Mem40_Centroid  Mean_Acc1298_Mean_Mem40_Rolloff  \\\n",
       "0                          0.034741                         0.089665   \n",
       "1                          0.081374                         0.272747   \n",
       "2                          0.110545                         0.273567   \n",
       "3                          0.042481                         0.199281   \n",
       "4                          0.074550                         0.140880   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_Flux  Mean_Acc1298_Mean_Mem40_MFCC_0  \\\n",
       "0                      0.091225                      -73.302422   \n",
       "1                      0.085733                      -62.584437   \n",
       "2                      0.084410                      -65.235325   \n",
       "3                      0.093447                      -80.305152   \n",
       "4                      0.079789                      -93.697749   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_1  Mean_Acc1298_Mean_Mem40_MFCC_2  \\\n",
       "0                        6.215179                        0.615074   \n",
       "1                        3.183163                       -0.218145   \n",
       "2                        2.794964                        0.639047   \n",
       "3                        5.824409                        0.648848   \n",
       "4                        5.543229                        1.064262   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_3  Mean_Acc1298_Mean_Mem40_MFCC_4  \\\n",
       "0                        2.037160                        0.804065   \n",
       "1                        0.163038                        0.620251   \n",
       "2                        1.281297                        0.757896   \n",
       "3                        1.754870                        1.495532   \n",
       "4                        0.899152                        0.890336   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_5  Mean_Acc1298_Mean_Mem40_MFCC_6  ...  \\\n",
       "0                        1.301409                        0.558576  ...   \n",
       "1                        0.458514                        0.041426  ...   \n",
       "2                        0.489412                        0.627636  ...   \n",
       "3                        0.739909                        0.809644  ...   \n",
       "4                        0.702328                        0.490685  ...   \n",
       "\n",
       "   BH_HighLowRatio    BHSUM1    BHSUM2    BHSUM3  amazed-suprised  \\\n",
       "0              2.0  0.245457  0.105065  0.405399             b'0'   \n",
       "1              2.0  0.343547  0.276366  0.710924             b'1'   \n",
       "2              3.0  0.188693  0.045941  0.457372             b'0'   \n",
       "3              2.0  0.102839  0.241934  0.351009             b'0'   \n",
       "4              2.0  0.195196  0.310801  0.683817             b'0'   \n",
       "\n",
       "   happy-pleased  relaxing-calm  quiet-still  sad-lonely  angry-aggresive  \n",
       "0           b'1'           b'1'         b'0'        b'0'             b'0'  \n",
       "1           b'0'           b'0'         b'0'        b'0'             b'1'  \n",
       "2           b'1'           b'0'         b'0'        b'0'             b'1'  \n",
       "3           b'0'           b'1'         b'0'        b'0'             b'0'  \n",
       "4           b'0'           b'0'         b'1'        b'0'             b'0'  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('emotions.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the keras model and dense layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bankNote.drop('class', axis=1).values\n",
    "y=bankNote['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2364c31be4c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X,y, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 950us/step - loss: 0.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6124641299247742"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the dataset\n",
    "emotions=pd.read_csv('emotions_out.csv')\n",
    "X=emotions.drop(columns=['amazed-suprised','happy-pleased','relaxing-calm','quiet-still','sad-lonely','angry-aggresive']).values\n",
    "y=emotions[['amazed-suprised','happy-pleased','relaxing-calm','quiet-still','sad-lonely','angry-aggresive']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                1825      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                520       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 96        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,756\n",
      "Trainable params: 2,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Secondly we will create model for emotions dataset\n",
    "# this is a categorical dataset\n",
    "model=Sequential()\n",
    "model.add(Dense(25, input_shape=(72,), activation=\"tanh\"))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics='accuracy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 14ms/step - loss: 3.3862 - accuracy: 0.2954 - val_loss: 3.5446 - val_accuracy: 0.2773\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3547 - accuracy: 0.2954 - val_loss: 3.5217 - val_accuracy: 0.2773\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3445 - accuracy: 0.2954 - val_loss: 3.5095 - val_accuracy: 0.2773\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3359 - accuracy: 0.2954 - val_loss: 3.4990 - val_accuracy: 0.3277\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3292 - accuracy: 0.3228 - val_loss: 3.4894 - val_accuracy: 0.3025\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3233 - accuracy: 0.2996 - val_loss: 3.4861 - val_accuracy: 0.3025\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3210 - accuracy: 0.3397 - val_loss: 3.4843 - val_accuracy: 0.3866\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3170 - accuracy: 0.3122 - val_loss: 3.4789 - val_accuracy: 0.3697\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3110 - accuracy: 0.3418 - val_loss: 3.4742 - val_accuracy: 0.3950\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3068 - accuracy: 0.3987 - val_loss: 3.4714 - val_accuracy: 0.3866\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3026 - accuracy: 0.4093 - val_loss: 3.4703 - val_accuracy: 0.3782\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3020 - accuracy: 0.3903 - val_loss: 3.4683 - val_accuracy: 0.3866\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3045 - accuracy: 0.3523 - val_loss: 3.4712 - val_accuracy: 0.3529\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3017 - accuracy: 0.4008 - val_loss: 3.4695 - val_accuracy: 0.3866\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3016 - accuracy: 0.4219 - val_loss: 3.4643 - val_accuracy: 0.4118\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3010 - accuracy: 0.4177 - val_loss: 3.4656 - val_accuracy: 0.3613\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2979 - accuracy: 0.3059 - val_loss: 3.4590 - val_accuracy: 0.2941\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2966 - accuracy: 0.2869 - val_loss: 3.4557 - val_accuracy: 0.2941\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2949 - accuracy: 0.2869 - val_loss: 3.4539 - val_accuracy: 0.2941\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2984 - accuracy: 0.2869 - val_loss: 3.4566 - val_accuracy: 0.2941\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2958 - accuracy: 0.2869 - val_loss: 3.4526 - val_accuracy: 0.2941\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2963 - accuracy: 0.2869 - val_loss: 3.4525 - val_accuracy: 0.2941\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2966 - accuracy: 0.2869 - val_loss: 3.4512 - val_accuracy: 0.2941\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2985 - accuracy: 0.2869 - val_loss: 3.4542 - val_accuracy: 0.2941\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2991 - accuracy: 0.2869 - val_loss: 3.4512 - val_accuracy: 0.2941\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3001 - accuracy: 0.2869 - val_loss: 3.4543 - val_accuracy: 0.2941\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3016 - accuracy: 0.2869 - val_loss: 3.4554 - val_accuracy: 0.2941\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3031 - accuracy: 0.2869 - val_loss: 3.4569 - val_accuracy: 0.2941\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3030 - accuracy: 0.2869 - val_loss: 3.4564 - val_accuracy: 0.2941\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3026 - accuracy: 0.2869 - val_loss: 3.4562 - val_accuracy: 0.2941\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3027 - accuracy: 0.2869 - val_loss: 3.4551 - val_accuracy: 0.2941\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3026 - accuracy: 0.2869 - val_loss: 3.4567 - val_accuracy: 0.2941\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3040 - accuracy: 0.2869 - val_loss: 3.4580 - val_accuracy: 0.2941\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2869 - val_loss: 3.4554 - val_accuracy: 0.2941\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3033 - accuracy: 0.2869 - val_loss: 3.4588 - val_accuracy: 0.2941\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3041 - accuracy: 0.2869 - val_loss: 3.4584 - val_accuracy: 0.2941\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3032 - accuracy: 0.2869 - val_loss: 3.4559 - val_accuracy: 0.2941\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3034 - accuracy: 0.2869 - val_loss: 3.4572 - val_accuracy: 0.2941\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3021 - accuracy: 0.2869 - val_loss: 3.4532 - val_accuracy: 0.2941\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3013 - accuracy: 0.2869 - val_loss: 3.4529 - val_accuracy: 0.2941\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3014 - accuracy: 0.2869 - val_loss: 3.4533 - val_accuracy: 0.2941\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3014 - accuracy: 0.2869 - val_loss: 3.4541 - val_accuracy: 0.2941\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3012 - accuracy: 0.2869 - val_loss: 3.4539 - val_accuracy: 0.2941\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3009 - accuracy: 0.2869 - val_loss: 3.4537 - val_accuracy: 0.2941\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3009 - accuracy: 0.2869 - val_loss: 3.4528 - val_accuracy: 0.2941\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3002 - accuracy: 0.2869 - val_loss: 3.4521 - val_accuracy: 0.2941\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2998 - accuracy: 0.2869 - val_loss: 3.4518 - val_accuracy: 0.2941\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3001 - accuracy: 0.2869 - val_loss: 3.4507 - val_accuracy: 0.2941\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3001 - accuracy: 0.2869 - val_loss: 3.4519 - val_accuracy: 0.2941\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2999 - accuracy: 0.2869 - val_loss: 3.4509 - val_accuracy: 0.2941\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2999 - accuracy: 0.2869 - val_loss: 3.4507 - val_accuracy: 0.2941\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2999 - accuracy: 0.2869 - val_loss: 3.4513 - val_accuracy: 0.2941\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3009 - accuracy: 0.2869 - val_loss: 3.4517 - val_accuracy: 0.2941\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3015 - accuracy: 0.2869 - val_loss: 3.4529 - val_accuracy: 0.2941\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3008 - accuracy: 0.2869 - val_loss: 3.4502 - val_accuracy: 0.2941\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2993 - accuracy: 0.2869 - val_loss: 3.4499 - val_accuracy: 0.2941\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2998 - accuracy: 0.2869 - val_loss: 3.4509 - val_accuracy: 0.2941\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2994 - accuracy: 0.2869 - val_loss: 3.4505 - val_accuracy: 0.2941\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2990 - accuracy: 0.2869 - val_loss: 3.4498 - val_accuracy: 0.2941\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2995 - accuracy: 0.2869 - val_loss: 3.4500 - val_accuracy: 0.2941\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2989 - accuracy: 0.2869 - val_loss: 3.4490 - val_accuracy: 0.2941\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2993 - accuracy: 0.2869 - val_loss: 3.4509 - val_accuracy: 0.2941\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2997 - accuracy: 0.2869 - val_loss: 3.4500 - val_accuracy: 0.2941\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2998 - accuracy: 0.2869 - val_loss: 3.4498 - val_accuracy: 0.2941\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2992 - accuracy: 0.2869 - val_loss: 3.4475 - val_accuracy: 0.2941\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2992 - accuracy: 0.2869 - val_loss: 3.4492 - val_accuracy: 0.2941\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2989 - accuracy: 0.2869 - val_loss: 3.4481 - val_accuracy: 0.2941\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2983 - accuracy: 0.2869 - val_loss: 3.4467 - val_accuracy: 0.2941\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2978 - accuracy: 0.2869 - val_loss: 3.4479 - val_accuracy: 0.2941\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2985 - accuracy: 0.2869 - val_loss: 3.4472 - val_accuracy: 0.2941\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2999 - accuracy: 0.2869 - val_loss: 3.4502 - val_accuracy: 0.2941\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2990 - accuracy: 0.2869 - val_loss: 3.4478 - val_accuracy: 0.2941\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2983 - accuracy: 0.2869 - val_loss: 3.4470 - val_accuracy: 0.2941\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2981 - accuracy: 0.2869 - val_loss: 3.4473 - val_accuracy: 0.2941\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2988 - accuracy: 0.2869 - val_loss: 3.4488 - val_accuracy: 0.2941\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2987 - accuracy: 0.2869 - val_loss: 3.4481 - val_accuracy: 0.2941\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2986 - accuracy: 0.2869 - val_loss: 3.4471 - val_accuracy: 0.2941\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3005 - accuracy: 0.2869 - val_loss: 3.4502 - val_accuracy: 0.2941\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2991 - accuracy: 0.2869 - val_loss: 3.4487 - val_accuracy: 0.2941\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2991 - accuracy: 0.2869 - val_loss: 3.4483 - val_accuracy: 0.2941\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2988 - accuracy: 0.2869 - val_loss: 3.4476 - val_accuracy: 0.2941\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2992 - accuracy: 0.2869 - val_loss: 3.4485 - val_accuracy: 0.2941\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2983 - accuracy: 0.2869 - val_loss: 3.4481 - val_accuracy: 0.2941\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2989 - accuracy: 0.2869 - val_loss: 3.4503 - val_accuracy: 0.2941\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2995 - accuracy: 0.2869 - val_loss: 3.4517 - val_accuracy: 0.2941\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3008 - accuracy: 0.2869 - val_loss: 3.4569 - val_accuracy: 0.2941\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3048 - accuracy: 0.2869 - val_loss: 3.4688 - val_accuracy: 0.2941\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3205 - accuracy: 0.2869 - val_loss: 3.4932 - val_accuracy: 0.2941\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3259 - accuracy: 0.2869 - val_loss: 3.4938 - val_accuracy: 0.2941\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3226 - accuracy: 0.2869 - val_loss: 3.4833 - val_accuracy: 0.2941\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3169 - accuracy: 0.2869 - val_loss: 3.4770 - val_accuracy: 0.2941\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3122 - accuracy: 0.2869 - val_loss: 3.4695 - val_accuracy: 0.2941\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3083 - accuracy: 0.2869 - val_loss: 3.4644 - val_accuracy: 0.2941\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3056 - accuracy: 0.2869 - val_loss: 3.4607 - val_accuracy: 0.2941\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3034 - accuracy: 0.2869 - val_loss: 3.4568 - val_accuracy: 0.2941\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3021 - accuracy: 0.2869 - val_loss: 3.4546 - val_accuracy: 0.2941\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3013 - accuracy: 0.2869 - val_loss: 3.4532 - val_accuracy: 0.2941\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3006 - accuracy: 0.2869 - val_loss: 3.4516 - val_accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3004 - accuracy: 0.2869 - val_loss: 3.4499 - val_accuracy: 0.2941\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2993 - accuracy: 0.2869 - val_loss: 3.4503 - val_accuracy: 0.2941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e5ef140d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 25)                1825      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                520       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 96        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,756\n",
      "Trainable params: 2,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Lastly we will create model for multi label\n",
    "# this is a categorical dataset\n",
    "model=Sequential()\n",
    "model.add(Dense(25, input_shape=(72,), activation=\"tanh\"))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics='accuracy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 837us/step - loss: 3.5050 - accuracy: 0.0725\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3928 - accuracy: 0.0877\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 997us/step - loss: 3.3411 - accuracy: 0.2024\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3259 - accuracy: 0.2884\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3217 - accuracy: 0.2884\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3234 - accuracy: 0.2884\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 994us/step - loss: 3.3250 - accuracy: 0.2884\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3253 - accuracy: 0.2884\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3248 - accuracy: 0.2884\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3246 - accuracy: 0.2884\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3223 - accuracy: 0.2884\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3188 - accuracy: 0.2884\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3168 - accuracy: 0.2884\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3165 - accuracy: 0.2884\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3137 - accuracy: 0.2884\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3169 - accuracy: 0.2884\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 998us/step - loss: 3.3153 - accuracy: 0.2884\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3179 - accuracy: 0.2884\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 940us/step - loss: 3.3182 - accuracy: 0.2884\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.3174 - accuracy: 0.2884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e606412e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 72)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9973494 , 0.9971874 , 0.9979739 , 0.99662703, 0.99704635,\n",
       "        0.99767977],\n",
       "       [0.9973477 , 0.9971852 , 0.9979691 , 0.99661744, 0.9970423 ,\n",
       "        0.99768007]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=X[1:3]\n",
    "print(sample.shape)\n",
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bankNote=pd.read_csv('banknote.csv')\n",
    "bankNote=shuffle(bankNote)\n",
    "X=bankNote.drop('class', axis=1).values\n",
    "y=bankNote['class'].values\n",
    "\n",
    "# First we will create model for bank note dataset\n",
    "# this is a binary dataset\n",
    "model=Sequential()\n",
    "model.add(Dense(2, input_shape=(4,), activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics='accuracy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 5ms/step - loss: 2.2422 - accuracy: 0.3729 - val_loss: 2.0751 - val_accuracy: 0.3617\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 2.0428 - accuracy: 0.3854 - val_loss: 1.8853 - val_accuracy: 0.3883\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.8651 - accuracy: 0.4000 - val_loss: 1.7038 - val_accuracy: 0.4005\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.6943 - accuracy: 0.3917 - val_loss: 1.5328 - val_accuracy: 0.4199\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.5358 - accuracy: 0.3979 - val_loss: 1.3663 - val_accuracy: 0.4150\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.3875 - accuracy: 0.3927 - val_loss: 1.2356 - val_accuracy: 0.4078\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.2606 - accuracy: 0.3917 - val_loss: 1.1026 - val_accuracy: 0.4078\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1479 - accuracy: 0.3896 - val_loss: 1.0122 - val_accuracy: 0.4345\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0636 - accuracy: 0.3969 - val_loss: 0.9566 - val_accuracy: 0.4563\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0059 - accuracy: 0.4177 - val_loss: 0.9149 - val_accuracy: 0.4854\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.4490 - val_loss: 0.8808 - val_accuracy: 0.4903\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.4573 - val_loss: 0.8520 - val_accuracy: 0.5121\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8879 - accuracy: 0.4719 - val_loss: 0.8264 - val_accuracy: 0.5243\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.4906 - val_loss: 0.8036 - val_accuracy: 0.5364\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8319 - accuracy: 0.5073 - val_loss: 0.7826 - val_accuracy: 0.5461\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8077 - accuracy: 0.5135 - val_loss: 0.7638 - val_accuracy: 0.5461\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7861 - accuracy: 0.5198 - val_loss: 0.7460 - val_accuracy: 0.5583\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7658 - accuracy: 0.5292 - val_loss: 0.7300 - val_accuracy: 0.5752\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.5479 - val_loss: 0.7156 - val_accuracy: 0.5825\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7314 - accuracy: 0.5615 - val_loss: 0.7018 - val_accuracy: 0.5922\n",
      "[0.37291666865348816, 0.3854166567325592, 0.4000000059604645, 0.3916666805744171, 0.39791667461395264, 0.39270833134651184, 0.3916666805744171, 0.3895833194255829, 0.3968749940395355, 0.4177083373069763, 0.4489583373069763, 0.4572916626930237, 0.47187501192092896, 0.4906249940395355, 0.5072916746139526, 0.5135416388511658, 0.5197916626930237, 0.5291666388511658, 0.5479166507720947, 0.5614583492279053]\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X, y, epochs=20, validation_split=0.3)\n",
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can print acc, val_loss, val_acc\n",
    "#now lets plot the graphs of accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "33/33 [==============================] - 1s 5ms/step - loss: 0.6797 - accuracy: 0.5996 - val_loss: 0.6698 - val_accuracy: 0.7055\n",
      "Epoch 2/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.7046 - val_loss: 0.6567 - val_accuracy: 0.7318\n",
      "Epoch 3/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.7396 - val_loss: 0.6409 - val_accuracy: 0.7551\n",
      "Epoch 4/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.7638 - val_loss: 0.6182 - val_accuracy: 0.7638\n",
      "Epoch 5/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7891 - val_loss: 0.5932 - val_accuracy: 0.7872\n",
      "Epoch 6/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.7940 - val_loss: 0.5654 - val_accuracy: 0.7843\n",
      "Epoch 7/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7920 - val_loss: 0.5364 - val_accuracy: 0.7813\n",
      "Epoch 8/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7911 - val_loss: 0.5069 - val_accuracy: 0.7843\n",
      "Epoch 9/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7901 - val_loss: 0.4772 - val_accuracy: 0.7843\n",
      "Epoch 10/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7891 - val_loss: 0.4453 - val_accuracy: 0.7872\n",
      "Epoch 11/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7881 - val_loss: 0.4066 - val_accuracy: 0.7872\n",
      "Epoch 12/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.7901 - val_loss: 0.3685 - val_accuracy: 0.7872\n",
      "Epoch 13/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.7920 - val_loss: 0.3355 - val_accuracy: 0.7901\n",
      "Epoch 14/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.7930 - val_loss: 0.3071 - val_accuracy: 0.7930\n",
      "Epoch 15/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.7949 - val_loss: 0.2839 - val_accuracy: 0.7959\n",
      "Epoch 16/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8008 - val_loss: 0.2649 - val_accuracy: 0.7988\n",
      "Epoch 17/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8047 - val_loss: 0.2485 - val_accuracy: 0.7988\n",
      "Epoch 18/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.8260 - val_loss: 0.2336 - val_accuracy: 0.9708\n",
      "Epoch 19/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9572 - val_loss: 0.2205 - val_accuracy: 0.9738\n",
      "Epoch 20/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9621 - val_loss: 0.2093 - val_accuracy: 0.9767\n",
      "Epoch 21/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9670 - val_loss: 0.1995 - val_accuracy: 0.9825\n",
      "Epoch 22/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9679 - val_loss: 0.1909 - val_accuracy: 0.9854\n",
      "Epoch 23/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9738 - val_loss: 0.1833 - val_accuracy: 0.9854\n",
      "Epoch 24/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9776 - val_loss: 0.1762 - val_accuracy: 0.9883\n",
      "Epoch 25/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9815 - val_loss: 0.1695 - val_accuracy: 0.9883\n",
      "Epoch 26/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9815 - val_loss: 0.1634 - val_accuracy: 0.9913\n",
      "Epoch 27/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9835 - val_loss: 0.1578 - val_accuracy: 0.9913\n",
      "Epoch 28/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9854 - val_loss: 0.1525 - val_accuracy: 0.9913\n",
      "Epoch 29/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9864 - val_loss: 0.1476 - val_accuracy: 0.9913\n",
      "Epoch 30/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9883 - val_loss: 0.1429 - val_accuracy: 0.9942\n",
      "Epoch 31/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9903 - val_loss: 0.1386 - val_accuracy: 0.9942\n",
      "Epoch 32/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9922 - val_loss: 0.1347 - val_accuracy: 0.9971\n",
      "Epoch 33/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9922 - val_loss: 0.1305 - val_accuracy: 0.9971\n",
      "Epoch 34/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9922 - val_loss: 0.1266 - val_accuracy: 0.9971\n",
      "Epoch 35/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9942 - val_loss: 0.1232 - val_accuracy: 0.9971\n",
      "Epoch 36/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9942 - val_loss: 0.1198 - val_accuracy: 0.9971\n",
      "Epoch 37/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9942 - val_loss: 0.1168 - val_accuracy: 0.9971\n",
      "Epoch 38/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9942 - val_loss: 0.1134 - val_accuracy: 0.9971\n",
      "Epoch 39/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9971\n",
      "Epoch 40/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9942 - val_loss: 0.1074 - val_accuracy: 0.9971\n",
      "Epoch 41/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9951 - val_loss: 0.1041 - val_accuracy: 0.9971\n",
      "Epoch 42/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9961 - val_loss: 0.1006 - val_accuracy: 0.9971\n",
      "Epoch 43/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9961 - val_loss: 0.0962 - val_accuracy: 0.9971\n",
      "Epoch 44/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9961 - val_loss: 0.0908 - val_accuracy: 0.9971\n",
      "Epoch 45/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9971 - val_loss: 0.0868 - val_accuracy: 0.9971\n",
      "Epoch 46/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9971 - val_loss: 0.0804 - val_accuracy: 0.9971\n",
      "Epoch 47/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9981 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9981 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9981 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9981 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9981 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9981 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9981 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9981 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9981 - val_loss: 0.0486 - val_accuracy: 0.9913\n",
      "Epoch 56/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9981 - val_loss: 0.0476 - val_accuracy: 0.9913\n",
      "Epoch 57/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9981 - val_loss: 0.0469 - val_accuracy: 0.9913\n",
      "Epoch 58/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9981 - val_loss: 0.0461 - val_accuracy: 0.9913\n",
      "Epoch 59/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9981 - val_loss: 0.0457 - val_accuracy: 0.9913\n",
      "Epoch 60/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9981 - val_loss: 0.0452 - val_accuracy: 0.9913\n",
      "Epoch 61/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9981 - val_loss: 0.0446 - val_accuracy: 0.9913\n",
      "Epoch 62/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9990 - val_loss: 0.0445 - val_accuracy: 0.9913\n",
      "Epoch 63/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9990 - val_loss: 0.0435 - val_accuracy: 0.9913\n",
      "Epoch 64/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 0.9913\n",
      "Epoch 65/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9990 - val_loss: 0.0426 - val_accuracy: 0.9913\n",
      "Epoch 66/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9990 - val_loss: 0.0418 - val_accuracy: 0.9913\n",
      "Epoch 67/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9990 - val_loss: 0.0413 - val_accuracy: 0.9913\n",
      "Epoch 68/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 0.0406 - val_accuracy: 0.9913\n",
      "Epoch 69/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9990 - val_loss: 0.0402 - val_accuracy: 0.9913\n",
      "Epoch 70/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9990 - val_loss: 0.0400 - val_accuracy: 0.9913\n",
      "Epoch 71/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9990 - val_loss: 0.0395 - val_accuracy: 0.9913\n",
      "Epoch 72/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9990 - val_loss: 0.0392 - val_accuracy: 0.9913\n",
      "Epoch 73/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9990 - val_loss: 0.0388 - val_accuracy: 0.9913\n",
      "Epoch 74/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.0386 - val_accuracy: 0.9913\n",
      "Epoch 75/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9990 - val_loss: 0.0383 - val_accuracy: 0.9913\n",
      "Epoch 76/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 0.9913\n",
      "Epoch 77/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9990 - val_loss: 0.0377 - val_accuracy: 0.9913\n",
      "Epoch 78/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9951 - val_loss: 0.0367 - val_accuracy: 0.9883\n",
      "Epoch 79/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9951 - val_loss: 0.0367 - val_accuracy: 0.9883\n",
      "Epoch 80/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9951 - val_loss: 0.0363 - val_accuracy: 0.9883\n",
      "Epoch 81/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9951 - val_loss: 0.0361 - val_accuracy: 0.9883\n",
      "Epoch 82/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9951 - val_loss: 0.0352 - val_accuracy: 0.9883\n",
      "Epoch 83/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9951 - val_loss: 0.0345 - val_accuracy: 0.9883\n",
      "Epoch 84/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9951 - val_loss: 0.0345 - val_accuracy: 0.9883\n",
      "Epoch 85/1000\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 0.0338 - val_accuracy: 0.9883\n",
      "Epoch 86/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9883\n",
      "Epoch 87/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.0331 - val_accuracy: 0.9883\n",
      "Epoch 88/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9951 - val_loss: 0.0329 - val_accuracy: 0.9883\n",
      "Epoch 89/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9951 - val_loss: 0.0325 - val_accuracy: 0.9883\n",
      "Epoch 90/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.0311 - val_accuracy: 0.9883\n",
      "Epoch 91/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9951 - val_loss: 0.0310 - val_accuracy: 0.9883\n",
      "Epoch 92/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9951 - val_loss: 0.0310 - val_accuracy: 0.9883\n",
      "Epoch 93/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0306 - val_accuracy: 0.9883\n",
      "Epoch 94/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.0303 - val_accuracy: 0.9883\n",
      "Epoch 95/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 0.0306 - val_accuracy: 0.9883\n",
      "Epoch 96/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.0301 - val_accuracy: 0.9883\n",
      "Epoch 97/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0297 - val_accuracy: 0.9883\n",
      "Epoch 98/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0298 - val_accuracy: 0.9883\n",
      "Epoch 99/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.0296 - val_accuracy: 0.9883\n",
      "Epoch 100/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.0291 - val_accuracy: 0.9883\n",
      "Epoch 101/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.0290 - val_accuracy: 0.9883\n",
      "Epoch 102/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.0290 - val_accuracy: 0.9883\n",
      "Epoch 103/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.0284 - val_accuracy: 0.9883\n",
      "Epoch 104/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.0286 - val_accuracy: 0.9883\n",
      "Epoch 105/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9951 - val_loss: 0.0286 - val_accuracy: 0.9883\n",
      "Epoch 106/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.0284 - val_accuracy: 0.9883\n",
      "Epoch 107/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.0286 - val_accuracy: 0.9883\n",
      "Epoch 108/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.0281 - val_accuracy: 0.9883\n",
      "Epoch 109/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0281 - val_accuracy: 0.9883\n",
      "Epoch 110/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0283 - val_accuracy: 0.9883\n",
      "Epoch 111/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.0279 - val_accuracy: 0.9883\n",
      "Epoch 112/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9951 - val_loss: 0.0277 - val_accuracy: 0.9883\n",
      "Epoch 113/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0280 - val_accuracy: 0.9883\n",
      "Epoch 114/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0272 - val_accuracy: 0.9883\n",
      "Epoch 115/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.0272 - val_accuracy: 0.9883\n",
      "Epoch 116/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.0269 - val_accuracy: 0.9883\n",
      "Epoch 117/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9883\n",
      "Epoch 118/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9883\n",
      "Epoch 119/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9883\n",
      "Epoch 120/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9883\n",
      "Epoch 121/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0264 - val_accuracy: 0.9883\n",
      "Epoch 122/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0261 - val_accuracy: 0.9883\n",
      "Epoch 123/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0260 - val_accuracy: 0.9883\n",
      "Epoch 124/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0257 - val_accuracy: 0.9883\n",
      "Epoch 125/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9883\n",
      "Epoch 126/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.0257 - val_accuracy: 0.9883\n",
      "Epoch 127/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0255 - val_accuracy: 0.9883\n",
      "Epoch 128/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0253 - val_accuracy: 0.9883\n",
      "Epoch 129/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0256 - val_accuracy: 0.9883\n",
      "Epoch 130/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0255 - val_accuracy: 0.9883\n",
      "Epoch 131/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0252 - val_accuracy: 0.9883\n",
      "Epoch 132/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0249 - val_accuracy: 0.9883\n",
      "Epoch 133/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0248 - val_accuracy: 0.9883\n",
      "Epoch 134/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0244 - val_accuracy: 0.9883\n",
      "Epoch 135/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0246 - val_accuracy: 0.9883\n",
      "Epoch 136/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0249 - val_accuracy: 0.9883\n",
      "Epoch 137/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0245 - val_accuracy: 0.9883\n",
      "Epoch 138/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.0242 - val_accuracy: 0.9883\n",
      "Epoch 139/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0241 - val_accuracy: 0.9883\n",
      "Epoch 140/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0239 - val_accuracy: 0.9883\n",
      "Epoch 141/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 0.0240 - val_accuracy: 0.9883\n",
      "Epoch 142/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0239 - val_accuracy: 0.9913\n",
      "Epoch 143/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0238 - val_accuracy: 0.9883\n",
      "Epoch 144/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0238 - val_accuracy: 0.9883\n",
      "Epoch 145/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0236 - val_accuracy: 0.9883\n",
      "Epoch 146/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0233 - val_accuracy: 0.9883\n",
      "Epoch 147/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0235 - val_accuracy: 0.9883\n",
      "Epoch 148/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9883\n",
      "Epoch 149/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: 0.0233 - val_accuracy: 0.9913\n",
      "Epoch 150/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 0.9913\n",
      "Epoch 151/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.0231 - val_accuracy: 0.9913\n",
      "Epoch 152/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9913\n",
      "Epoch 153/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9913\n",
      "Epoch 154/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 0.9913\n",
      "Epoch 155/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 0.0231 - val_accuracy: 0.9913\n",
      "Epoch 156/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 0.0230 - val_accuracy: 0.9913\n",
      "Epoch 157/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9913\n",
      "Epoch 158/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9913\n",
      "Epoch 159/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9990 - val_loss: 0.0228 - val_accuracy: 0.9913\n",
      "Epoch 160/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9990 - val_loss: 0.0226 - val_accuracy: 0.9913\n",
      "Epoch 161/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9913\n",
      "Epoch 162/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9990 - val_loss: 0.0225 - val_accuracy: 0.9913\n",
      "Epoch 163/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9913\n",
      "Epoch 164/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9913\n",
      "Epoch 165/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.0224 - val_accuracy: 0.9913\n",
      "Epoch 166/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.0222 - val_accuracy: 0.9913\n",
      "Epoch 167/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9990 - val_loss: 0.0224 - val_accuracy: 0.9913\n",
      "Epoch 168/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9913\n",
      "Epoch 169/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9913\n",
      "Epoch 170/1000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9913\n",
      "Epoch 171/1000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9990 - val_loss: 0.0224 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e64d9fb80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import early stopping from keras callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Instantiate an early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Train your model with the callback\n",
    "model.fit(X_train, y_train, epochs=1000,validation_data=(X_test, y_test),callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9913\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9913\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 0.0219 - val_accuracy: 0.9913\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9913\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9913\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9913\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9913\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9913\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9913\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9913\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9913\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9913\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9913\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9913\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9913\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9913\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9990 - val_loss: 0.0209 - val_accuracy: 0.9913\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9913\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9913\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9913\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9913\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9913\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9990 - val_loss: 0.0202 - val_accuracy: 0.9913\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9913\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9913\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.0204 - val_accuracy: 0.9913\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9913\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9913\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.0201 - val_accuracy: 0.9913\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9913\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9913\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9913\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9913\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9913\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9913\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9913\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9913\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.0198 - val_accuracy: 0.9913\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9913\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9913\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0189 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9913\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9913\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9913\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9913\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9913\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9913\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9913\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9913\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9913\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.0187 - val_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9913\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9913\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9913\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9913\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9913\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9913\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9913\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9913\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9913\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9913\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9913\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9913\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9913\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9913\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9913\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9913\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9913\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9913\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9913\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9913\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9913\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9913\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9913\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9913\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9913\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9913\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9913\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9913\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9913\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e6603bc10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import model checkpoint from keras callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# Instantiate a model checkpoint callback\n",
    "model_save = ModelCheckpoint('best_model.hdf5', save_best_only=True)\n",
    "# Train your model with the callback\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test),callbacks = [model_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 25)                1825      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 25)               100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 20)               80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 15)                315       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 15)               60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 6)                 96        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,996\n",
      "Trainable params: 2,876\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 16ms/step - loss: 4.0629 - accuracy: 0.1266 - val_loss: 3.7107 - val_accuracy: 0.2773\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.6018 - accuracy: 0.1561 - val_loss: 3.6660 - val_accuracy: 0.2773\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.5040 - accuracy: 0.1962 - val_loss: 3.6230 - val_accuracy: 0.2773\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3837 - accuracy: 0.2743 - val_loss: 3.5859 - val_accuracy: 0.2773\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3815 - accuracy: 0.2722 - val_loss: 3.5531 - val_accuracy: 0.2773\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2451 - accuracy: 0.2954 - val_loss: 3.5213 - val_accuracy: 0.2689\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2310 - accuracy: 0.3228 - val_loss: 3.4980 - val_accuracy: 0.2689\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1658 - accuracy: 0.3291 - val_loss: 3.4753 - val_accuracy: 0.2521\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2078 - accuracy: 0.3376 - val_loss: 3.4542 - val_accuracy: 0.2689\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1640 - accuracy: 0.3629 - val_loss: 3.4337 - val_accuracy: 0.3361\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1130 - accuracy: 0.3903 - val_loss: 3.4162 - val_accuracy: 0.3866\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1599 - accuracy: 0.3987 - val_loss: 3.3973 - val_accuracy: 0.3782\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1341 - accuracy: 0.3924 - val_loss: 3.3753 - val_accuracy: 0.3782\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1104 - accuracy: 0.4156 - val_loss: 3.3530 - val_accuracy: 0.3782\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1729 - accuracy: 0.4051 - val_loss: 3.3386 - val_accuracy: 0.3277\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.1377 - accuracy: 0.3776 - val_loss: 3.3452 - val_accuracy: 0.3025\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2335 - accuracy: 0.3671 - val_loss: 3.3349 - val_accuracy: 0.2773\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2459 - accuracy: 0.3840 - val_loss: 3.3193 - val_accuracy: 0.3109\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2555 - accuracy: 0.3819 - val_loss: 3.8189 - val_accuracy: 0.2689\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.2096 - accuracy: 0.3882 - val_loss: 3.2978 - val_accuracy: 0.3529\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3094 - accuracy: 0.3861 - val_loss: 4.0887 - val_accuracy: 0.2437\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.4108 - accuracy: 0.3502 - val_loss: 3.4000 - val_accuracy: 0.3109\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4209 - accuracy: 0.3544 - val_loss: 3.3588 - val_accuracy: 0.3025\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.3924 - accuracy: 0.4114 - val_loss: 6.2619 - val_accuracy: 0.2857\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.5683 - accuracy: 0.3734 - val_loss: 3.9523 - val_accuracy: 0.3361\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.4829 - accuracy: 0.3755 - val_loss: 10.0320 - val_accuracy: 0.2437\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.6256 - accuracy: 0.3671 - val_loss: 3.8065 - val_accuracy: 0.2941\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.5657 - accuracy: 0.3713 - val_loss: 7.6868 - val_accuracy: 0.2521\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.7483 - accuracy: 0.3819 - val_loss: 8.1915 - val_accuracy: 0.2017\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5902 - accuracy: 0.3629 - val_loss: 9.0701 - val_accuracy: 0.2017\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.5751 - accuracy: 0.3481 - val_loss: 14.2536 - val_accuracy: 0.2605\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7175 - accuracy: 0.3270 - val_loss: 4.5443 - val_accuracy: 0.3361\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6881 - accuracy: 0.3080 - val_loss: 17.8491 - val_accuracy: 0.2857\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.7699 - accuracy: 0.3333 - val_loss: 7.8885 - val_accuracy: 0.2605\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5833 - accuracy: 0.3481 - val_loss: 14.8914 - val_accuracy: 0.2689\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.8762 - accuracy: 0.3143 - val_loss: 18.0925 - val_accuracy: 0.2437\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.8262 - accuracy: 0.3312 - val_loss: 13.3181 - val_accuracy: 0.2857\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.7161 - accuracy: 0.3333 - val_loss: 6.1815 - val_accuracy: 0.3025\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.8862 - accuracy: 0.3228 - val_loss: 18.9537 - val_accuracy: 0.2269\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.9097 - accuracy: 0.3165 - val_loss: 14.8533 - val_accuracy: 0.2437\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.1631 - accuracy: 0.3376 - val_loss: 5.4914 - val_accuracy: 0.2605\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.2696 - accuracy: 0.3397 - val_loss: 19.8178 - val_accuracy: 0.2185\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.9974 - accuracy: 0.3228 - val_loss: 11.1240 - val_accuracy: 0.2017\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 3.8939 - accuracy: 0.3354 - val_loss: 7.7966 - val_accuracy: 0.2605\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.3106 - accuracy: 0.3143 - val_loss: 15.0871 - val_accuracy: 0.2353\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.3764 - accuracy: 0.3143 - val_loss: 5.9760 - val_accuracy: 0.2269\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.1647 - accuracy: 0.3523 - val_loss: 11.9321 - val_accuracy: 0.1513\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.3448 - accuracy: 0.3418 - val_loss: 15.4168 - val_accuracy: 0.1681\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.4109 - accuracy: 0.3186 - val_loss: 9.1285 - val_accuracy: 0.2101\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.7407 - accuracy: 0.3460 - val_loss: 9.7831 - val_accuracy: 0.1681\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.5724 - accuracy: 0.3397 - val_loss: 10.1513 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.4106 - accuracy: 0.3165 - val_loss: 6.1529 - val_accuracy: 0.2857\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.7653 - accuracy: 0.3059 - val_loss: 12.7268 - val_accuracy: 0.1176\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.8751 - accuracy: 0.3333 - val_loss: 5.2696 - val_accuracy: 0.2353\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 4.9420 - accuracy: 0.3270 - val_loss: 9.7363 - val_accuracy: 0.1345\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.1260 - accuracy: 0.3270 - val_loss: 6.1084 - val_accuracy: 0.2437\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.2172 - accuracy: 0.3312 - val_loss: 9.5007 - val_accuracy: 0.1513\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.5162 - accuracy: 0.3460 - val_loss: 8.2756 - val_accuracy: 0.1933\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.3191 - accuracy: 0.3523 - val_loss: 8.1142 - val_accuracy: 0.1933\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.3165 - val_loss: 18.9283 - val_accuracy: 0.1261\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.5425 - accuracy: 0.3354 - val_loss: 11.4825 - val_accuracy: 0.2017\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.2733 - accuracy: 0.3418 - val_loss: 6.3546 - val_accuracy: 0.2857\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.2660 - accuracy: 0.3207 - val_loss: 13.5407 - val_accuracy: 0.1261\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.3470 - accuracy: 0.3207 - val_loss: 6.7678 - val_accuracy: 0.2605\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.1256 - accuracy: 0.3333 - val_loss: 6.1232 - val_accuracy: 0.2689\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.2983 - accuracy: 0.3418 - val_loss: 9.7201 - val_accuracy: 0.1849\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.2419 - accuracy: 0.3228 - val_loss: 6.3542 - val_accuracy: 0.3361\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.6553 - accuracy: 0.3228 - val_loss: 7.3932 - val_accuracy: 0.2605\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.4843 - accuracy: 0.3460 - val_loss: 7.0250 - val_accuracy: 0.2773\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 5.8046 - accuracy: 0.3228 - val_loss: 9.2229 - val_accuracy: 0.2857\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 6.0330 - accuracy: 0.3249 - val_loss: 6.2440 - val_accuracy: 0.2941\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.3063 - accuracy: 0.3333 - val_loss: 5.6947 - val_accuracy: 0.3025\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.5694 - accuracy: 0.3101 - val_loss: 7.7992 - val_accuracy: 0.2353\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.2451 - accuracy: 0.3059 - val_loss: 6.6258 - val_accuracy: 0.2857\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.2682 - accuracy: 0.3481 - val_loss: 6.9165 - val_accuracy: 0.2353\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.7927 - accuracy: 0.3333 - val_loss: 6.6992 - val_accuracy: 0.3109\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.4443 - accuracy: 0.3312 - val_loss: 8.4586 - val_accuracy: 0.2353\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.3130 - accuracy: 0.3228 - val_loss: 10.7810 - val_accuracy: 0.2437\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.5900 - accuracy: 0.3249 - val_loss: 5.2092 - val_accuracy: 0.3193\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.6510 - accuracy: 0.3397 - val_loss: 8.0096 - val_accuracy: 0.2437\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.4585 - accuracy: 0.2954 - val_loss: 6.0232 - val_accuracy: 0.2353\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.9053 - accuracy: 0.3354 - val_loss: 6.3658 - val_accuracy: 0.2353\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.0490 - accuracy: 0.3270 - val_loss: 11.8386 - val_accuracy: 0.1681\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.9678 - accuracy: 0.3249 - val_loss: 11.3777 - val_accuracy: 0.1513\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.8541 - accuracy: 0.3228 - val_loss: 6.4934 - val_accuracy: 0.2941\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 6.9182 - accuracy: 0.3544 - val_loss: 7.2553 - val_accuracy: 0.2353\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.7458 - accuracy: 0.3228 - val_loss: 6.5602 - val_accuracy: 0.2605\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.3316 - accuracy: 0.3143 - val_loss: 11.6338 - val_accuracy: 0.1849\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.8848 - accuracy: 0.3481 - val_loss: 13.3075 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.8218 - accuracy: 0.3333 - val_loss: 39.0450 - val_accuracy: 0.1597\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.7144 - accuracy: 0.3165 - val_loss: 8.2451 - val_accuracy: 0.2185\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 8.2346 - accuracy: 0.3523 - val_loss: 13.3410 - val_accuracy: 0.2689\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.7888 - accuracy: 0.3312 - val_loss: 6.8957 - val_accuracy: 0.2773\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 8.7140 - accuracy: 0.3165 - val_loss: 8.3808 - val_accuracy: 0.2857\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 8.3681 - accuracy: 0.3207 - val_loss: 7.7074 - val_accuracy: 0.2689\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 9.8586 - accuracy: 0.3101 - val_loss: 7.5103 - val_accuracy: 0.2773\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.9087 - accuracy: 0.3354 - val_loss: 7.8009 - val_accuracy: 0.2101\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 9.0030 - accuracy: 0.3608 - val_loss: 8.5682 - val_accuracy: 0.2605\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 9.4570 - accuracy: 0.3418 - val_loss: 10.4838 - val_accuracy: 0.3025\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 9.2400 - accuracy: 0.3165 - val_loss: 25.8822 - val_accuracy: 0.1849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24e661e8a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing the dataset\n",
    "emotions=pd.read_csv('emotions_out.csv')\n",
    "X=emotions.drop(columns=['amazed-suprised','happy-pleased','relaxing-calm','quiet-still','sad-lonely','angry-aggresive']).values\n",
    "y=emotions[['amazed-suprised','happy-pleased','relaxing-calm','quiet-still','sad-lonely','angry-aggresive']].values\n",
    "\n",
    "# Secondly we will create model for emotions dataset\n",
    "# this is a categorical dataset\n",
    "model=Sequential()\n",
    "model.add(Dense(25, input_shape=(72,), activation=\"tanh\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics='accuracy')\n",
    "model.summary()\n",
    "model.fit(X,y, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "1. Number of layers\n",
    "2. Number of neurons per layer\n",
    "3. Layer order\n",
    "4. Layer activation\n",
    "5. Batch Sizes\n",
    "6. Learning Rates\n",
    "7. Optimizers\n",
    "8. Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
