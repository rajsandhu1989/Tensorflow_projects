{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the desired APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decalre a tensorflow constant and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4])>\n",
      "[1 2 3 4]\n",
      "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4])>\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "# Declare a constant, we need to import constant from tensorflow\n",
    "sample_constant=tf.constant(20)\n",
    "print(sample_constant.dtype)\n",
    "# Now we can perform some operations using tensorlfow in this constant\n",
    "#Similarly, we can create variables also\n",
    "A1=tf.Variable([1,2,3,4])\n",
    "print(A1)\n",
    "#Above created variable can be printed using the numpy conversion\n",
    "print(A1.numpy())\n",
    "B1=A1.numpy()\n",
    "\n",
    "B1=tf.Variable(B1)\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Tensor Constants and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [4] vs. [3,2] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-91b8810e4929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#B1=tf.ones_like(A1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mB23\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mC1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mC23\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7107\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4] vs. [3,2] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "#Ones function\n",
    "A1=tf.ones([3,2], tf.int32)\n",
    "#print(A1.numpy())\n",
    "\n",
    "#Zeros function\n",
    "B1=tf.zeros([3,2], tf.int32)\n",
    "#print(B1)\n",
    "\n",
    "A1=tf.constant([1,2,3,4])\n",
    "A23=tf.constant([[1,2,3], [4,5,6]])\n",
    "\n",
    "#create ones tensor and perform element wise multiplication\n",
    "B1=tf.ones_like(A1)\n",
    "B23=tf.ones_like(A23)\n",
    "C1=tf.multiply(A1,B1)\n",
    "C23=tf.multiply(A23, B23)\n",
    "print(C1.numpy())\n",
    "#fill method\n",
    "c33=tf.fill([3,3], 7)\n",
    "#print(c33.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 10 10]\n",
      " [10 10 10]\n",
      " [10 10 10]]\n"
     ]
    }
   ],
   "source": [
    "#create two tensors\n",
    "a1=tf.fill([3,3], 7)\n",
    "a2=tf.fill([3,3], 3)\n",
    "#Add the two tensors\n",
    "a3=tf.add(a1,a2)\n",
    "#print final tensor\n",
    "print(a3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[100]\n",
      " [200]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "#create feature value\n",
    "feat_value=tf.constant([[1,12],[2,13],[3,14]])\n",
    "parameters=tf.constant([[100],[200]])\n",
    "print(parameters)\n",
    "\n",
    "#create predictions by matrix multiplication\n",
    "pred=tf.matmul(feat_value, parameters)\n",
    "#print(pred)\n",
    "\n",
    "# if we define actual value, we can have errors\n",
    "actual=[[110], [120],[130]]\n",
    "error=actual-pred\n",
    "#print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(45, shape=(), dtype=int32)\n",
      "tf.Tensor([13 15 17], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute All as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:All]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-522b60f3c4ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7107\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute All as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:All]"
     ]
    }
   ],
   "source": [
    "#we can reduce the value of tensor\n",
    "feat_value=tf.constant([[1,12],[2,13],[3,14]])\n",
    "pred=tf.reduce_sum(feat_value)\n",
    "print(pred)\n",
    "\n",
    "#we can reduce at any dimension also\n",
    "print(tf.reduce_sum(feat_value, 1))\n",
    "\n",
    "print(tf.reduce_all(feat_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "# Define x\n",
    "x = tf.Variable(6.0)\n",
    "\n",
    "# Define y within instance of GradientTape\n",
    "with tf.GradientTape() as gt:\n",
    "  gt.watch(x)\n",
    "  y = tf.multiply(x, x)\n",
    "  \n",
    "#Evaluate the gradient of y at x = 6\n",
    "g = gt.gradient(y, x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to reshape a picture so that it can be feed to neural network\n",
    "#lets say we have a 28*28 grayscale image\n",
    "image=tf.random.uniform([28,28], maxval=255, dtype='int32')\n",
    "image_reshape=tf.reshape(image, [28*28,1])\n",
    "#this is required when we input an image to the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three losses most commonly used\n",
    "#Mean Absolute Error\n",
    "#tf.keras.losses.mae()\n",
    "#Mean squared error\n",
    "#tf.keras.losses.mse()\n",
    "#Huber Error\n",
    "#tf.keras.losses.huber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "mpg=pd.read_csv('auto-mpg.csv')\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.horsepower=mpg.horsepower.str.replace(\"?\", \"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.horsepower=pd.to_numeric(mpg.horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "housing=pd.read_csv('kc_house_data.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract mpg and horsepower from the dataset\n",
    "mpg_1=np.array(mpg['mpg'], np.float32)\n",
    "horsepower=np.array(mpg['horsepower'], np.float32)\n",
    "\n",
    "#define the intercept and slope\n",
    "intercept=tf.Variable(0.2, np.float32)\n",
    "slope=tf.Variable(0.2, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'housing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c936f473b4f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Extract price and sqft for the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sqft_living'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Lets define the intercept and slope of the linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'housing' is not defined"
     ]
    }
   ],
   "source": [
    "#Extract price and sqft for the dataset\n",
    "price=np.array(housing['price'], np.float32)\n",
    "size=np.array(housing['sqft_living'], np.float32)\n",
    "\n",
    "#Lets define the intercept and slope of the linear regression\n",
    "intercept=tf.Variable(0.2, np.float32)\n",
    "slope=tf.Variable(0.5, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.5856\n",
      "216.08374\n",
      "215.6073\n",
      "215.15659\n",
      "214.73186\n",
      "214.33328\n",
      "213.96086\n",
      "213.61464\n",
      "213.29439\n",
      "212.99985\n",
      "212.73062\n",
      "212.4862\n",
      "212.26591\n",
      "212.06895\n",
      "211.89441\n",
      "211.74127\n",
      "211.60826\n",
      "211.49423\n",
      "211.39769\n",
      "211.31728\n",
      "211.25139\n",
      "211.19852\n",
      "211.15703\n",
      "211.1254\n",
      "211.10204\n",
      "211.08551\n",
      "211.0743\n",
      "211.06723\n",
      "211.063\n",
      "211.0606\n",
      "211.0591\n",
      "211.05772\n",
      "211.05586\n",
      "211.053\n",
      "211.04878\n",
      "211.04303\n",
      "211.03561\n",
      "211.02654\n",
      "211.01578\n",
      "211.00362\n",
      "210.99013\n",
      "210.97554\n",
      "210.96019\n",
      "210.94417\n",
      "210.92784\n",
      "210.9114\n",
      "210.89502\n",
      "210.87889\n",
      "210.8631\n",
      "210.84789\n",
      "210.83322\n",
      "210.8192\n",
      "210.80579\n",
      "210.79309\n",
      "210.78098\n",
      "210.7694\n",
      "210.7583\n",
      "210.74774\n",
      "210.73746\n",
      "210.72752\n",
      "210.71777\n",
      "210.70815\n",
      "210.69861\n",
      "210.68913\n",
      "210.67964\n",
      "210.67009\n",
      "210.66048\n",
      "210.65076\n",
      "210.64098\n",
      "210.63109\n",
      "210.6211\n",
      "210.61108\n",
      "210.601\n",
      "210.59085\n",
      "210.58067\n",
      "210.5705\n",
      "210.56029\n",
      "210.55014\n",
      "210.54001\n",
      "210.52989\n",
      "210.51985\n",
      "210.50984\n",
      "210.49985\n",
      "210.48991\n",
      "210.48001\n",
      "210.47017\n",
      "210.46034\n",
      "210.45055\n",
      "210.4408\n",
      "210.43102\n",
      "210.42128\n",
      "210.41153\n",
      "210.4018\n",
      "210.39204\n",
      "210.38234\n",
      "210.3726\n",
      "210.36287\n",
      "210.35313\n",
      "210.34338\n",
      "210.33363\n",
      "210.32388\n",
      "210.31415\n",
      "210.30441\n",
      "210.29468\n",
      "210.28493\n",
      "210.27527\n",
      "210.2655\n",
      "210.25581\n",
      "210.24611\n",
      "210.23642\n",
      "210.22672\n",
      "210.21704\n",
      "210.20737\n",
      "210.19771\n",
      "210.18803\n",
      "210.17836\n",
      "210.1687\n",
      "210.15906\n",
      "210.1494\n",
      "210.13974\n",
      "210.1301\n",
      "210.12045\n",
      "210.1108\n",
      "210.10117\n",
      "210.09154\n",
      "210.0819\n",
      "210.07224\n",
      "210.06264\n",
      "210.05302\n",
      "210.04338\n",
      "210.03377\n",
      "210.02412\n",
      "210.01451\n",
      "210.00491\n",
      "209.99527\n",
      "209.98569\n",
      "209.97607\n",
      "209.96648\n",
      "209.9569\n",
      "209.94728\n",
      "209.9377\n",
      "209.92809\n",
      "209.91853\n",
      "209.90892\n",
      "209.89932\n",
      "209.88976\n",
      "209.88019\n",
      "209.8706\n",
      "209.86101\n",
      "209.85147\n",
      "209.84189\n",
      "209.83232\n",
      "209.82272\n",
      "209.81319\n",
      "209.80363\n",
      "209.79402\n",
      "209.78448\n",
      "209.77493\n",
      "209.76537\n",
      "209.75583\n",
      "209.74625\n",
      "209.73672\n",
      "209.72717\n",
      "209.71764\n",
      "209.70808\n",
      "209.69853\n",
      "209.68901\n",
      "209.67947\n",
      "209.6699\n",
      "209.66035\n",
      "209.65085\n",
      "209.64131\n",
      "209.63176\n",
      "209.62225\n",
      "209.61275\n",
      "209.60321\n",
      "209.5937\n",
      "209.58415\n",
      "209.57465\n",
      "209.56516\n",
      "209.5556\n",
      "209.5461\n",
      "209.53659\n",
      "209.52707\n",
      "209.51756\n",
      "209.50804\n",
      "209.49857\n",
      "209.48906\n",
      "209.4795\n",
      "209.47005\n",
      "209.46048\n",
      "209.45102\n",
      "209.44154\n",
      "209.432\n",
      "209.42255\n",
      "209.41304\n",
      "209.40356\n",
      "209.39403\n",
      "209.38458\n",
      "209.37506\n",
      "209.3656\n",
      "209.3561\n",
      "209.34662\n",
      "209.3371\n",
      "209.32765\n",
      "209.31815\n",
      "209.30869\n",
      "209.29921\n",
      "209.2897\n",
      "209.28024\n",
      "209.27077\n",
      "209.26132\n",
      "209.25185\n",
      "209.24234\n",
      "209.23288\n",
      "209.22339\n",
      "209.21393\n",
      "209.2045\n",
      "209.19502\n",
      "209.18556\n",
      "209.1761\n",
      "209.16661\n",
      "209.15717\n",
      "209.14769\n",
      "209.13824\n",
      "209.12881\n",
      "209.11932\n",
      "209.10988\n",
      "209.10042\n",
      "209.09096\n",
      "209.0815\n",
      "209.07204\n",
      "209.06262\n",
      "209.05313\n",
      "209.04372\n",
      "209.03427\n",
      "209.02483\n",
      "209.0154\n",
      "209.00595\n",
      "208.99649\n",
      "208.98705\n",
      "208.97762\n",
      "208.96819\n",
      "208.95872\n",
      "208.9493\n",
      "208.93985\n",
      "208.93044\n",
      "208.92099\n",
      "208.91154\n",
      "208.90215\n",
      "208.89267\n",
      "208.88329\n",
      "208.87384\n",
      "208.8644\n",
      "208.85498\n",
      "208.84555\n",
      "208.83614\n",
      "208.82666\n",
      "208.81728\n",
      "208.80785\n",
      "208.7984\n",
      "208.789\n",
      "208.77959\n",
      "208.77016\n",
      "208.76074\n",
      "208.75133\n",
      "208.74193\n",
      "208.7325\n",
      "208.72308\n",
      "208.71368\n",
      "208.70424\n",
      "208.69484\n",
      "208.68542\n",
      "208.67601\n",
      "208.6666\n",
      "208.6572\n",
      "208.6478\n",
      "208.63838\n",
      "208.62898\n",
      "208.61954\n",
      "208.61015\n",
      "208.60078\n",
      "208.59135\n",
      "208.58197\n",
      "208.57253\n",
      "208.56314\n",
      "208.55374\n",
      "208.54434\n",
      "208.53497\n",
      "208.52556\n",
      "208.51617\n",
      "208.50679\n",
      "208.49738\n",
      "208.488\n",
      "208.47859\n",
      "208.46921\n",
      "208.45982\n",
      "208.45044\n",
      "208.44101\n",
      "208.43161\n",
      "208.42224\n",
      "208.41283\n",
      "208.40349\n",
      "208.39407\n",
      "208.38467\n",
      "208.37532\n",
      "208.3659\n",
      "208.35652\n",
      "208.34717\n",
      "208.33778\n",
      "208.3284\n",
      "208.319\n",
      "208.30965\n",
      "208.30025\n",
      "208.29086\n",
      "208.28148\n",
      "208.27211\n",
      "208.26274\n",
      "208.25337\n",
      "208.24397\n",
      "208.23463\n",
      "208.22525\n",
      "208.21588\n",
      "208.2065\n",
      "208.19711\n",
      "208.18777\n",
      "208.17839\n",
      "208.16902\n",
      "208.15967\n",
      "208.1503\n",
      "208.14095\n",
      "208.13158\n",
      "208.1222\n",
      "208.11282\n",
      "208.10349\n",
      "208.0941\n",
      "208.08475\n",
      "208.0754\n",
      "208.066\n",
      "208.05666\n",
      "208.04729\n",
      "208.03795\n",
      "208.02858\n",
      "208.0192\n",
      "208.00986\n",
      "208.00049\n",
      "207.99115\n",
      "207.9818\n",
      "207.97244\n",
      "207.9631\n",
      "207.95374\n",
      "207.94437\n",
      "207.93504\n",
      "207.92569\n",
      "207.91634\n",
      "207.90698\n",
      "207.89761\n",
      "207.88829\n",
      "207.87895\n",
      "207.8696\n",
      "207.86021\n",
      "207.85089\n",
      "207.84154\n",
      "207.83221\n",
      "207.82286\n",
      "207.8135\n",
      "207.80415\n",
      "207.79485\n",
      "207.78549\n",
      "207.77615\n",
      "207.76678\n",
      "207.75746\n",
      "207.74814\n",
      "207.73877\n",
      "207.72946\n",
      "207.72011\n",
      "207.71078\n",
      "207.7014\n",
      "207.6921\n",
      "207.68279\n",
      "207.67343\n",
      "207.66408\n",
      "207.65479\n",
      "207.64545\n",
      "207.63611\n",
      "207.62674\n",
      "207.61745\n",
      "207.60812\n",
      "207.59875\n",
      "207.58948\n",
      "207.58012\n",
      "207.5708\n",
      "207.56148\n",
      "207.55214\n",
      "207.54283\n",
      "207.5335\n",
      "207.52417\n",
      "207.51482\n",
      "207.50554\n",
      "207.49622\n",
      "207.48686\n",
      "207.47754\n",
      "207.46825\n",
      "207.4589\n",
      "207.44957\n",
      "207.44026\n",
      "207.43097\n",
      "207.42165\n",
      "207.4123\n",
      "207.40298\n",
      "207.39369\n",
      "207.38437\n",
      "207.37505\n",
      "207.36572\n",
      "207.35643\n",
      "207.34709\n",
      "207.3378\n",
      "207.32848\n",
      "207.31917\n",
      "207.30984\n",
      "207.30055\n",
      "207.29123\n",
      "207.28192\n",
      "207.2726\n",
      "207.26329\n",
      "207.25398\n",
      "207.24467\n",
      "207.23538\n",
      "207.22606\n",
      "207.21677\n",
      "207.20746\n",
      "207.19817\n",
      "207.18886\n",
      "207.17953\n",
      "207.17021\n",
      "207.16092\n",
      "207.15164\n",
      "207.14233\n",
      "207.13303\n",
      "207.12372\n",
      "207.11443\n",
      "207.10515\n",
      "207.09583\n",
      "207.08653\n",
      "207.07721\n",
      "207.06793\n",
      "207.05864\n",
      "207.04935\n",
      "207.04004\n",
      "207.03075\n",
      "207.02145\n",
      "207.01218\n",
      "207.00285\n",
      "206.99358\n",
      "206.98428\n",
      "206.97498\n",
      "206.96571\n",
      "206.95639\n",
      "206.94711\n",
      "206.93779\n",
      "206.92851\n",
      "206.91925\n",
      "206.90996\n",
      "206.90068\n",
      "206.89136\n",
      "206.88208\n",
      "206.87279\n",
      "206.86351\n",
      "206.85425\n",
      "206.84492\n",
      "206.83566\n",
      "206.82639\n",
      "206.81708\n",
      "206.80779\n",
      "206.79851\n",
      "206.78925\n",
      "206.77997\n",
      "206.77069\n",
      "206.76138\n",
      "206.7521\n",
      "206.74286\n",
      "206.73357\n",
      "206.72429\n",
      "206.71498\n",
      "206.70572\n",
      "206.69643\n",
      "206.68716\n",
      "206.67789\n",
      "206.66861\n",
      "206.65933\n",
      "206.65007\n",
      "206.64081\n",
      "206.63152\n",
      "206.62225\n",
      "206.61296\n",
      "206.60368\n",
      "206.59444\n",
      "206.58516\n",
      "206.57588\n",
      "206.56659\n",
      "206.55734\n",
      "206.5481\n",
      "206.53879\n",
      "206.52953\n",
      "206.52028\n",
      "206.51099\n",
      "206.50174\n",
      "206.49246\n",
      "206.4832\n",
      "206.47394\n",
      "206.46465\n",
      "206.45543\n",
      "206.44614\n",
      "206.43687\n",
      "206.42761\n",
      "206.41833\n",
      "206.40907\n",
      "206.39983\n",
      "206.39056\n",
      "206.38129\n",
      "206.37204\n",
      "206.36278\n",
      "206.35353\n",
      "206.34425\n",
      "206.33504\n",
      "206.32574\n",
      "206.31648\n",
      "206.30722\n",
      "206.29797\n",
      "206.28871\n",
      "206.27946\n",
      "206.27023\n",
      "206.26094\n",
      "206.2517\n",
      "206.24246\n",
      "206.2332\n",
      "206.22394\n",
      "206.21466\n",
      "206.20544\n",
      "206.19618\n",
      "206.1869\n",
      "206.17769\n",
      "206.16843\n",
      "206.15918\n",
      "206.14993\n",
      "206.14069\n",
      "206.13144\n",
      "206.12218\n",
      "206.11293\n",
      "206.10368\n",
      "206.09444\n",
      "206.0852\n",
      "206.07594\n",
      "206.0667\n",
      "206.05743\n",
      "206.0482\n",
      "206.03897\n",
      "206.02972\n",
      "206.02048\n",
      "206.01125\n",
      "206.002\n",
      "205.99275\n",
      "205.98354\n",
      "205.97429\n",
      "205.96506\n",
      "205.95578\n",
      "205.94655\n",
      "205.93732\n",
      "205.92809\n",
      "205.91881\n",
      "205.9096\n",
      "205.90038\n",
      "205.89116\n",
      "205.88187\n",
      "205.87267\n",
      "205.86343\n",
      "205.85419\n",
      "205.84497\n",
      "205.83571\n",
      "205.82652\n",
      "205.81725\n",
      "205.808\n",
      "205.79878\n",
      "205.78954\n",
      "205.7803\n",
      "205.7711\n",
      "205.76186\n",
      "205.75266\n",
      "205.74341\n",
      "205.73418\n",
      "205.72493\n",
      "205.71571\n",
      "205.70648\n",
      "205.69724\n",
      "205.68805\n",
      "205.67882\n",
      "205.66957\n",
      "205.66035\n",
      "205.65112\n",
      "205.64192\n",
      "205.63269\n",
      "205.62347\n",
      "205.61423\n",
      "205.60504\n",
      "205.5958\n",
      "205.58656\n",
      "205.57735\n",
      "205.56813\n",
      "205.55888\n",
      "205.54967\n",
      "205.54045\n",
      "205.53123\n",
      "205.522\n",
      "205.51282\n",
      "205.50359\n",
      "205.49437\n",
      "205.48514\n",
      "205.47594\n",
      "205.46672\n",
      "205.45749\n",
      "205.44827\n",
      "205.43907\n",
      "205.42984\n",
      "205.42064\n",
      "205.4114\n",
      "205.40222\n",
      "205.39297\n",
      "205.38379\n",
      "205.37457\n",
      "205.36534\n",
      "205.35616\n",
      "205.34695\n",
      "205.33772\n",
      "205.32849\n",
      "205.31929\n",
      "205.3101\n",
      "205.30087\n",
      "205.29167\n",
      "205.28244\n",
      "205.27325\n",
      "205.26405\n",
      "205.25485\n",
      "205.24562\n",
      "205.23643\n",
      "205.2272\n",
      "205.218\n",
      "205.20882\n",
      "205.19962\n",
      "205.1904\n",
      "205.1812\n",
      "205.172\n",
      "205.16281\n",
      "205.15363\n",
      "205.1444\n",
      "205.1352\n",
      "205.12598\n",
      "205.11679\n",
      "205.10757\n",
      "205.09836\n",
      "205.0892\n",
      "205.07997\n",
      "205.07079\n",
      "205.0616\n",
      "205.05238\n",
      "205.04318\n",
      "205.03401\n",
      "205.02481\n",
      "205.01562\n",
      "205.00642\n",
      "204.99721\n",
      "204.98802\n",
      "204.97884\n",
      "204.96965\n",
      "204.96045\n",
      "204.95125\n",
      "204.94205\n",
      "204.93285\n",
      "204.92366\n",
      "204.91449\n",
      "204.90529\n",
      "204.8961\n",
      "204.8869\n",
      "204.87769\n",
      "204.86852\n",
      "204.85931\n",
      "204.85013\n",
      "204.84093\n",
      "204.83176\n",
      "204.82257\n",
      "204.81339\n",
      "204.8042\n",
      "204.79503\n",
      "204.7858\n",
      "204.77664\n",
      "204.76746\n",
      "204.75827\n",
      "204.74911\n",
      "204.73991\n",
      "204.73073\n",
      "204.72151\n",
      "204.71237\n",
      "204.70319\n",
      "204.69398\n",
      "204.68481\n",
      "204.67564\n",
      "204.66644\n",
      "204.65729\n",
      "204.64809\n",
      "204.6389\n",
      "204.62973\n",
      "204.62053\n",
      "204.61136\n",
      "204.6022\n",
      "204.593\n",
      "204.58383\n",
      "204.57465\n",
      "204.56549\n",
      "204.55632\n",
      "204.54713\n",
      "204.53795\n",
      "204.52876\n",
      "204.5196\n",
      "204.51042\n",
      "204.50122\n",
      "204.4921\n",
      "204.48291\n",
      "204.47371\n",
      "204.46455\n",
      "204.4554\n",
      "204.44621\n",
      "204.43704\n",
      "204.42786\n",
      "204.41872\n",
      "204.40955\n",
      "204.4004\n",
      "204.39119\n",
      "204.38203\n",
      "204.37286\n",
      "204.36371\n",
      "204.35452\n",
      "204.34535\n",
      "204.33617\n",
      "204.32704\n",
      "204.31787\n",
      "204.30869\n",
      "204.29955\n",
      "204.29037\n",
      "204.28119\n",
      "204.27205\n",
      "204.26286\n",
      "204.25372\n",
      "204.24454\n",
      "204.23538\n",
      "204.22623\n",
      "204.21706\n",
      "204.2079\n",
      "204.19873\n",
      "204.18958\n",
      "204.18042\n",
      "204.17126\n",
      "204.1621\n",
      "204.15295\n",
      "204.14377\n",
      "204.1346\n",
      "204.12546\n",
      "204.1163\n",
      "204.10713\n",
      "204.09798\n",
      "204.08882\n",
      "204.07968\n",
      "204.07054\n",
      "204.06136\n",
      "204.05222\n",
      "204.04306\n",
      "204.03392\n",
      "204.02475\n",
      "204.01558\n",
      "204.00644\n",
      "203.99727\n",
      "203.98814\n",
      "203.97897\n",
      "203.9698\n",
      "203.96068\n",
      "203.95154\n",
      "203.94237\n",
      "203.93324\n",
      "203.92409\n",
      "203.91493\n",
      "203.90579\n",
      "203.8966\n",
      "203.88748\n",
      "203.87836\n",
      "203.86919\n",
      "203.86002\n",
      "203.85088\n",
      "203.84175\n",
      "203.83263\n",
      "203.82346\n",
      "203.8143\n",
      "203.80519\n",
      "203.79604\n",
      "203.78688\n",
      "203.77771\n",
      "203.76862\n",
      "203.75946\n",
      "203.75029\n",
      "203.74115\n",
      "203.73204\n",
      "203.72287\n",
      "203.71376\n",
      "203.70459\n",
      "203.69545\n",
      "203.68633\n",
      "203.67717\n",
      "203.66806\n",
      "203.65892\n",
      "203.64975\n",
      "203.64064\n",
      "203.63148\n",
      "203.62234\n",
      "203.61322\n",
      "203.60405\n",
      "203.59494\n",
      "203.58582\n",
      "203.57668\n",
      "203.56752\n",
      "203.55838\n",
      "203.54927\n",
      "203.54015\n",
      "203.53102\n",
      "203.52187\n",
      "203.51276\n",
      "203.50359\n",
      "203.49449\n",
      "203.48532\n",
      "203.47621\n",
      "203.4671\n",
      "203.45793\n",
      "203.44882\n",
      "203.43968\n",
      "203.43056\n",
      "203.42145\n",
      "203.41234\n",
      "203.40315\n",
      "203.39406\n",
      "203.38493\n",
      "203.37578\n",
      "203.36668\n",
      "203.35754\n",
      "203.34842\n",
      "203.3393\n",
      "203.33017\n",
      "203.32104\n",
      "203.3119\n",
      "203.30278\n",
      "203.29367\n",
      "203.28453\n",
      "203.2754\n",
      "203.26631\n",
      "203.25717\n",
      "203.24806\n",
      "203.23892\n",
      "203.22983\n",
      "203.22072\n",
      "203.21156\n",
      "203.20244\n",
      "203.19333\n",
      "203.1842\n",
      "203.1751\n",
      "203.16597\n",
      "203.15686\n",
      "203.14774\n",
      "203.1386\n",
      "203.12952\n",
      "203.1204\n",
      "203.11125\n",
      "203.10217\n",
      "203.09305\n",
      "203.08391\n",
      "203.07481\n",
      "203.06566\n",
      "203.05656\n",
      "203.04749\n",
      "203.03831\n",
      "203.02925\n",
      "203.02014\n",
      "203.01102\n",
      "203.0019\n",
      "202.99278\n",
      "202.98367\n",
      "202.97456\n",
      "202.96544\n",
      "202.95633\n",
      "202.94725\n",
      "202.93813\n",
      "202.929\n",
      "202.9199\n",
      "202.91078\n",
      "202.90167\n",
      "202.8926\n",
      "202.88348\n",
      "202.87436\n",
      "202.86522\n",
      "202.85617\n",
      "202.84706\n",
      "202.83794\n",
      "202.82883\n",
      "202.81972\n",
      "202.81062\n",
      "202.80153\n",
      "202.7924\n",
      "202.78331\n",
      "202.77422\n",
      "202.76509\n",
      "202.75603\n",
      "202.7469\n",
      "202.7378\n",
      "202.7287\n",
      "202.71957\n",
      "202.71048\n",
      "202.70142\n",
      "202.69229\n",
      "202.6832\n",
      "202.67409\n",
      "202.66498\n",
      "202.6559\n",
      "202.6468\n",
      "202.63773\n",
      "202.62859\n",
      "202.61952\n",
      "202.61041\n",
      "202.6013\n",
      "202.59222\n",
      "202.58311\n",
      "202.57402\n",
      "202.56491\n",
      "202.55585\n",
      "202.54674\n",
      "202.53764\n",
      "202.52853\n",
      "202.51945\n",
      "202.51039\n",
      "202.50128\n",
      "202.49219\n",
      "202.48308\n",
      "202.47398\n",
      "202.4649\n",
      "202.45581\n",
      "202.44675\n",
      "202.43765\n",
      "202.42854\n",
      "202.41943\n",
      "202.41037\n",
      "202.40129\n",
      "202.3922\n",
      "202.3831\n",
      "202.37402\n",
      "202.36493\n",
      "202.35587\n",
      "202.34677\n",
      "202.33766\n",
      "202.3286\n",
      "202.3195\n",
      "202.31042\n",
      "202.30135\n",
      "202.29224\n",
      "202.28316\n",
      "202.27408\n",
      "202.265\n",
      "202.25594\n",
      "202.24684\n",
      "202.23775\n",
      "202.22868\n",
      "202.21959\n",
      "202.21048\n",
      "202.20142\n",
      "202.19232\n",
      "202.18327\n",
      "202.1742\n",
      "202.1651\n",
      "202.15604\n",
      "202.14697\n",
      "202.13788\n",
      "202.12878\n",
      "202.11967\n",
      "202.11066\n",
      "202.10156\n",
      "202.09247\n",
      "202.0834\n",
      "202.07434\n",
      "202.06525\n",
      "202.0562\n",
      "202.04713\n",
      "202.03804\n",
      "202.02895\n",
      "202.01987\n",
      "202.01077\n",
      "202.00172\n",
      "201.99261\n",
      "201.9836\n",
      "The final intercept and slope is \n",
      "1.2100391 0.16986209\n"
     ]
    }
   ],
   "source": [
    "#create a linear regression using y=mx+b\n",
    "def linear_regression(intercept, slope, features=horsepower):\n",
    "    return slope*features+intercept\n",
    "\n",
    "#create a loss function\n",
    "def loss_function(intercept, slope, target=mpg_1, features=horsepower):\n",
    "    #create predictions\n",
    "    pred=linear_regression(intercept, slope, features)\n",
    "    loss= tf.keras.losses.mse(target, pred)\n",
    "    return loss\n",
    "\n",
    "#create an instance of optimizer\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "#minimize the loss using epochs\n",
    "epochs=1000\n",
    "for i in range(epochs):\n",
    "    opt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "    print(np.array(loss_function(intercept, slope)))\n",
    "\n",
    "print(\"The final intercept and slope is \")\n",
    "print(np.array(intercept),np.array(slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create mini batch for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942.33386\n",
      "731.5999\n",
      "753.14734\n",
      "824.88605\n",
      "773.96454\n",
      "625.4507\n",
      "637.02234\n",
      "345.61276\n",
      "435.6385\n",
      "517.33057\n",
      "415.6559\n",
      "364.77145\n",
      "352.2754\n",
      "243.6855\n",
      "274.18185\n",
      "136.71828\n",
      "326.82562\n",
      "151.83792\n",
      "262.96674\n",
      "224.68994\n",
      "113.33562\n",
      "137.7689\n",
      "91.50354\n",
      "38.625496\n",
      "79.891426\n",
      "81.71806\n",
      "30.313824\n",
      "53.161907\n",
      "79.358536\n",
      "19.634678\n",
      "27.072891\n",
      "12.378161\n",
      "15.471376\n",
      "30.36055\n",
      "28.984318\n",
      "48.231403\n",
      "76.472466\n",
      "121.84408\n",
      "229.32634\n",
      "239.61314\n",
      "0.12790832 0.12922105\n"
     ]
    }
   ],
   "source": [
    "#Lets define the intercept and slope of the linear regression\n",
    "intercept=tf.Variable(0.1, np.float32)\n",
    "slope=tf.Variable(0.1, np.float32)\n",
    "#create a linear regression using y=mx+b\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return slope*features+intercept\n",
    "\n",
    "#create a loss function\n",
    "def loss_function(intercept, slope, target, features):\n",
    "    #create predictions\n",
    "    pred=linear_regression(intercept, slope, features)\n",
    "    loss= tf.keras.losses.mse(target, pred)\n",
    "    return loss\n",
    "\n",
    "#create an instance of optimizer\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "\n",
    "#create minibatch from the csv file\n",
    "\n",
    "for batch in pd.read_csv('auto-mpg.csv', chunksize=10):\n",
    "    mpg_batch=np.array(batch['mpg'], np.float32)\n",
    "    horsepower_batch=np.array(batch['horsepower'], np.float32)\n",
    "    opt.minimize(lambda:loss_function(intercept, slope, mpg_batch, horsepower_batch), var_list=[intercept, slope])\n",
    "    print(np.array(loss_function(intercept, slope,mpg_batch, horsepower_batch)))\n",
    "\n",
    "print(intercept.numpy(), slope.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layers (Multiple Layer NN)\n",
    "#### Lets Create a simple dense neural network using keras API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take UCI credit card details\n",
    "credit_data=pd.read_csv('uci_credit_card.csv')\n",
    "input=credit_data.drop(['ID','default.payment.next.month'], axis=1)\n",
    "output=credit_data['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 23)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change input as tensorflow constant\n",
    "input_net=tf.constant(input, tf.float32)\n",
    "output_net=tf.constant(output, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define the weights using the normal distribution\n",
    "# Define the layer 1 weights (keep in mind the number of neurons)\n",
    "w1 = tf.Variable(tf.random.normal([23, 10]))\n",
    "# Initialize the layer 1 bias\n",
    "b1 = tf.Variable(tf.ones([10]))\n",
    "# Define the layer 2 weights\n",
    "w2 = tf.Variable(tf.random.normal([10,1]))\n",
    "# Define the layer 2 bias\n",
    "b2 = tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = input_net):\n",
    "\t# Apply relu activation functions to layer 1\n",
    "\tlayer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n",
    "    # Apply dropout rate of 0.25\n",
    "\tdropout = tf.keras.layers.Dropout(0.25)(layer1)\n",
    "\treturn tf.keras.activations.sigmoid(tf.matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = input_net, targets = output_net):\n",
    "\tpredictions = model(w1, b1, w2, b2)\n",
    "\t# Pass targets and predictions to the cross entropy loss\n",
    "\treturn tf.keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), var_list=[w1,b1,w2,b2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 20501.6074 - accuracy: 0.5739 - val_loss: 28.9320 - val_accuracy: 0.9965\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 15.9148 - accuracy: 0.9973 - val_loss: 7.5832 - val_accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.2534 - accuracy: 0.9990 - val_loss: 3.2337 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.4845 - accuracy: 0.9995 - val_loss: 2.9797 - val_accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9497 - accuracy: 0.9995 - val_loss: 2.7672 - val_accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.9996 - val_loss: 2.7135 - val_accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.9996 - val_loss: 2.6674 - val_accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.9997 - val_loss: 2.5869 - val_accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.9997 - val_loss: 2.5184 - val_accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 0.4150 - accuracy: 0.9997 - val_loss: 2.4304 - val_accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "#create s sequential model\n",
    "model=keras.Sequential()\n",
    "#add first layer\n",
    "model.add(Dense(10,activation='relu', input_shape=(23,)))\n",
    "#add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#compile the model with optimizer and loss\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#fit the model and check the accuracy\n",
    "history=model.fit(input_net, output_net, batch_size=100, epochs=10, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 10)                240       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000001609616FEB0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
