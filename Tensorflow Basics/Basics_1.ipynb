{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the desired APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decalre a tensorflow constant and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4])>\n",
      "[1 2 3 4]\n",
      "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4])>\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "# Declare a constant, we need to import constant from tensorflow\n",
    "sample_constant=tf.constant(20)\n",
    "print(sample_constant.dtype)\n",
    "# Now we can perform some operations using tensorlfow in this constant\n",
    "#Similarly, we can create variables also\n",
    "A1=tf.Variable([1,2,3,4])\n",
    "print(A1)\n",
    "#Above created variable can be printed using the numpy conversion\n",
    "print(A1.numpy())\n",
    "B1=A1.numpy()\n",
    "\n",
    "B1=tf.Variable(B1)\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Tensor Constants and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [4] vs. [3,2] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-91b8810e4929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#B1=tf.ones_like(A1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mB23\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mC1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mC23\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7107\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4] vs. [3,2] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "#Ones function\n",
    "A1=tf.ones([3,2], tf.int32)\n",
    "#print(A1.numpy())\n",
    "\n",
    "#Zeros function\n",
    "B1=tf.zeros([3,2], tf.int32)\n",
    "#print(B1)\n",
    "\n",
    "A1=tf.constant([1,2,3,4])\n",
    "A23=tf.constant([[1,2,3], [4,5,6]])\n",
    "\n",
    "#create ones tensor and perform element wise multiplication\n",
    "B1=tf.ones_like(A1)\n",
    "B23=tf.ones_like(A23)\n",
    "C1=tf.multiply(A1,B1)\n",
    "C23=tf.multiply(A23, B23)\n",
    "print(C1.numpy())\n",
    "#fill method\n",
    "c33=tf.fill([3,3], 7)\n",
    "#print(c33.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 10 10]\n",
      " [10 10 10]\n",
      " [10 10 10]]\n"
     ]
    }
   ],
   "source": [
    "#create two tensors\n",
    "a1=tf.fill([3,3], 7)\n",
    "a2=tf.fill([3,3], 3)\n",
    "#Add the two tensors\n",
    "a3=tf.add(a1,a2)\n",
    "#print final tensor\n",
    "print(a3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[100]\n",
      " [200]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "#create feature value\n",
    "feat_value=tf.constant([[1,12],[2,13],[3,14]])\n",
    "parameters=tf.constant([[100],[200]])\n",
    "print(parameters)\n",
    "\n",
    "#create predictions by matrix multiplication\n",
    "pred=tf.matmul(feat_value, parameters)\n",
    "#print(pred)\n",
    "\n",
    "# if we define actual value, we can have errors\n",
    "actual=[[110], [120],[130]]\n",
    "error=actual-pred\n",
    "#print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(45, shape=(), dtype=int32)\n",
      "tf.Tensor([13 15 17], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute All as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:All]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-522b60f3c4ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7107\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute All as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:All]"
     ]
    }
   ],
   "source": [
    "#we can reduce the value of tensor\n",
    "feat_value=tf.constant([[1,12],[2,13],[3,14]])\n",
    "pred=tf.reduce_sum(feat_value)\n",
    "print(pred)\n",
    "\n",
    "#we can reduce at any dimension also\n",
    "print(tf.reduce_sum(feat_value, 1))\n",
    "\n",
    "print(tf.reduce_all(feat_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "# Define x\n",
    "x = tf.Variable(6.0)\n",
    "\n",
    "# Define y within instance of GradientTape\n",
    "with tf.GradientTape() as gt:\n",
    "  gt.watch(x)\n",
    "  y = tf.multiply(x, x)\n",
    "  \n",
    "#Evaluate the gradient of y at x = 6\n",
    "g = gt.gradient(y, x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to reshape a picture so that it can be feed to neural network\n",
    "#lets say we have a 28*28 grayscale image\n",
    "image=tf.random.uniform([28,28], maxval=255, dtype='int32')\n",
    "image_reshape=tf.reshape(image, [28*28,1])\n",
    "#this is required when we input an image to the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three losses most commonly used\n",
    "#Mean Absolute Error\n",
    "#tf.keras.losses.mae()\n",
    "#Mean squared error\n",
    "#tf.keras.losses.mse()\n",
    "#Huber Error\n",
    "#tf.keras.losses.huber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "mpg=pd.read_csv('auto-mpg.csv')\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.horsepower=mpg.horsepower.str.replace(\"?\", \"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.horsepower=pd.to_numeric(mpg.horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "housing=pd.read_csv('kc_house_data.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract mpg and horsepower from the dataset\n",
    "mpg_1=np.array(mpg['mpg'], np.float32)\n",
    "horsepower=np.array(mpg['horsepower'], np.float32)\n",
    "\n",
    "#define the intercept and slope\n",
    "intercept=tf.Variable(0.1, np.float32)\n",
    "slope=tf.Variable(0.1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract price and sqft for the dataset\n",
    "price=np.array(housing['price'], np.float32)\n",
    "size=np.array(housing['sqft_living'], np.float32)\n",
    "\n",
    "#Lets define the intercept and slope of the linear regression\n",
    "intercept=tf.Variable(0.1, np.float32)\n",
    "slope=tf.Variable(0.1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287.8667\n",
      "285.9213\n",
      "284.0021\n",
      "282.1096\n",
      "280.24414\n",
      "278.40613\n",
      "276.59586\n",
      "274.81375\n",
      "273.06\n",
      "271.33502\n",
      "269.63895\n",
      "267.97205\n",
      "266.3346\n",
      "264.72668\n",
      "263.14847\n",
      "261.60013\n",
      "260.08163\n",
      "258.5932\n",
      "257.13477\n",
      "255.7064\n",
      "254.30804\n",
      "252.93967\n",
      "251.60121\n",
      "250.29256\n",
      "249.0136\n",
      "247.76425\n",
      "246.54422\n",
      "245.35344\n",
      "244.19164\n",
      "243.05864\n",
      "241.95409\n",
      "240.87787\n",
      "239.82957\n",
      "238.80894\n",
      "237.81563\n",
      "236.84937\n",
      "235.90974\n",
      "234.99643\n",
      "234.10904\n",
      "233.24725\n",
      "232.41058\n",
      "231.59866\n",
      "230.81107\n",
      "230.04742\n",
      "229.30728\n",
      "228.59026\n",
      "227.89581\n",
      "227.22356\n",
      "226.57307\n",
      "225.94394\n",
      "225.3356\n",
      "224.74773\n",
      "224.17981\n",
      "223.63136\n",
      "223.10196\n",
      "222.59116\n",
      "222.09856\n",
      "221.62363\n",
      "221.166\n",
      "220.72514\n",
      "220.30064\n",
      "219.89212\n",
      "219.49904\n",
      "219.12111\n",
      "218.75777\n",
      "218.40869\n",
      "218.07338\n",
      "217.75146\n",
      "217.44258\n",
      "217.14624\n",
      "216.86212\n",
      "216.5898\n",
      "216.3289\n",
      "216.07909\n",
      "215.83994\n",
      "215.61111\n",
      "215.39227\n",
      "215.18309\n",
      "214.98314\n",
      "214.79214\n",
      "214.60977\n",
      "214.43573\n",
      "214.26965\n",
      "214.1113\n",
      "213.96034\n",
      "213.8165\n",
      "213.67946\n",
      "213.54898\n",
      "213.4248\n",
      "213.30666\n",
      "213.19426\n",
      "213.0874\n",
      "212.98589\n",
      "212.88943\n",
      "212.79779\n",
      "212.71086\n",
      "212.62828\n",
      "212.54996\n",
      "212.47565\n",
      "212.4052\n",
      "212.33841\n",
      "212.2751\n",
      "212.21512\n",
      "212.15831\n",
      "212.10449\n",
      "212.05351\n",
      "212.00526\n",
      "211.95955\n",
      "211.9163\n",
      "211.87537\n",
      "211.83661\n",
      "211.79991\n",
      "211.76521\n",
      "211.73233\n",
      "211.70125\n",
      "211.67174\n",
      "211.64384\n",
      "211.6174\n",
      "211.59236\n",
      "211.56862\n",
      "211.5461\n",
      "211.52469\n",
      "211.50441\n",
      "211.48514\n",
      "211.46684\n",
      "211.44943\n",
      "211.43286\n",
      "211.41707\n",
      "211.40205\n",
      "211.3877\n",
      "211.37398\n",
      "211.36084\n",
      "211.3483\n",
      "211.33627\n",
      "211.3247\n",
      "211.31364\n",
      "211.30296\n",
      "211.29265\n",
      "211.28276\n",
      "211.27316\n",
      "211.2639\n",
      "211.25493\n",
      "211.24619\n",
      "211.23775\n",
      "211.22949\n",
      "211.22144\n",
      "211.21361\n",
      "211.20593\n",
      "211.19844\n",
      "211.19107\n",
      "211.18387\n",
      "211.17679\n",
      "211.16977\n",
      "211.16292\n",
      "211.15616\n",
      "211.14944\n",
      "211.1428\n",
      "211.13629\n",
      "211.12978\n",
      "211.12335\n",
      "211.11697\n",
      "211.11066\n",
      "211.10435\n",
      "211.09811\n",
      "211.09189\n",
      "211.08568\n",
      "211.07954\n",
      "211.07338\n",
      "211.06725\n",
      "211.06114\n",
      "211.05502\n",
      "211.04893\n",
      "211.04285\n",
      "211.03679\n",
      "211.03072\n",
      "211.02463\n",
      "211.01859\n",
      "211.01253\n",
      "211.00645\n",
      "211.00037\n",
      "210.9943\n",
      "210.98827\n",
      "210.98216\n",
      "210.97609\n",
      "210.97\n",
      "210.96393\n",
      "210.9578\n",
      "210.9517\n",
      "210.94559\n",
      "210.9395\n",
      "210.93333\n",
      "210.92722\n",
      "210.92107\n",
      "210.9149\n",
      "210.90878\n",
      "210.9026\n",
      "210.89641\n",
      "210.89023\n",
      "210.88405\n",
      "210.87782\n",
      "210.87163\n",
      "210.86542\n",
      "210.85916\n",
      "210.85295\n",
      "210.84668\n",
      "210.84044\n",
      "210.83417\n",
      "210.8279\n",
      "210.8216\n",
      "210.8153\n",
      "210.80902\n",
      "210.8027\n",
      "210.7964\n",
      "210.79007\n",
      "210.78372\n",
      "210.7774\n",
      "210.77103\n",
      "210.76471\n",
      "210.7583\n",
      "210.75192\n",
      "210.7455\n",
      "210.73912\n",
      "210.73273\n",
      "210.7263\n",
      "210.7199\n",
      "210.71349\n",
      "210.70703\n",
      "210.70058\n",
      "210.69414\n",
      "210.68765\n",
      "210.68124\n",
      "210.6747\n",
      "210.66823\n",
      "210.66173\n",
      "210.65524\n",
      "210.64873\n",
      "210.6422\n",
      "210.6357\n",
      "210.62917\n",
      "210.6226\n",
      "210.61607\n",
      "210.60956\n",
      "210.60294\n",
      "210.59637\n",
      "210.5898\n",
      "210.58325\n",
      "210.57663\n",
      "210.56999\n",
      "210.56345\n",
      "210.5568\n",
      "210.55017\n",
      "210.54352\n",
      "210.53693\n",
      "210.53027\n",
      "210.52364\n",
      "210.51698\n",
      "210.5103\n",
      "210.50363\n",
      "210.49693\n",
      "210.49026\n",
      "210.48357\n",
      "210.47688\n",
      "210.47017\n",
      "210.46342\n",
      "210.45671\n",
      "210.45\n",
      "210.44327\n",
      "210.43652\n",
      "210.42978\n",
      "210.42302\n",
      "210.41626\n",
      "210.40948\n",
      "210.40274\n",
      "210.39597\n",
      "210.38913\n",
      "210.38239\n",
      "210.37556\n",
      "210.36877\n",
      "210.36197\n",
      "210.35513\n",
      "210.34833\n",
      "210.34148\n",
      "210.33464\n",
      "210.3278\n",
      "210.32094\n",
      "210.3141\n",
      "210.30724\n",
      "210.30035\n",
      "210.29347\n",
      "210.2866\n",
      "210.27974\n",
      "210.27284\n",
      "210.26595\n",
      "210.259\n",
      "210.2521\n",
      "210.2452\n",
      "210.23827\n",
      "210.23135\n",
      "210.2244\n",
      "210.2175\n",
      "210.21053\n",
      "210.20358\n",
      "210.19662\n",
      "210.18964\n",
      "210.18271\n",
      "210.17574\n",
      "210.16873\n",
      "210.16176\n",
      "210.15479\n",
      "210.14775\n",
      "210.14076\n",
      "210.13377\n",
      "210.12674\n",
      "210.1197\n",
      "210.11272\n",
      "210.1057\n",
      "210.09863\n",
      "210.09158\n",
      "210.08456\n",
      "210.07751\n",
      "210.07045\n",
      "210.06339\n",
      "210.05634\n",
      "210.04926\n",
      "210.04219\n",
      "210.0351\n",
      "210.02802\n",
      "210.02092\n",
      "210.01382\n",
      "210.00671\n",
      "209.99963\n",
      "209.99248\n",
      "209.98538\n",
      "209.97827\n",
      "209.97115\n",
      "209.964\n",
      "209.95688\n",
      "209.94972\n",
      "209.94258\n",
      "209.9354\n",
      "209.92825\n",
      "209.92111\n",
      "209.91394\n",
      "209.90675\n",
      "209.89958\n",
      "209.8924\n",
      "209.88522\n",
      "209.87804\n",
      "209.87082\n",
      "209.86363\n",
      "209.85641\n",
      "209.84924\n",
      "209.84201\n",
      "209.83478\n",
      "209.82753\n",
      "209.82033\n",
      "209.8131\n",
      "209.80588\n",
      "209.79861\n",
      "209.7914\n",
      "209.78412\n",
      "209.77687\n",
      "209.76959\n",
      "209.76233\n",
      "209.75507\n",
      "209.7478\n",
      "209.74055\n",
      "209.73323\n",
      "209.72595\n",
      "209.71863\n",
      "209.7114\n",
      "209.70407\n",
      "209.69676\n",
      "209.68944\n",
      "209.68213\n",
      "209.67482\n",
      "209.66751\n",
      "209.6602\n",
      "209.65285\n",
      "209.64551\n",
      "209.63817\n",
      "209.63084\n",
      "209.6235\n",
      "209.61613\n",
      "209.60881\n",
      "209.60144\n",
      "209.59407\n",
      "209.58675\n",
      "209.57932\n",
      "209.57195\n",
      "209.56458\n",
      "209.55722\n",
      "209.5498\n",
      "209.54243\n",
      "209.53503\n",
      "209.52762\n",
      "209.52026\n",
      "209.51283\n",
      "209.50542\n",
      "209.498\n",
      "209.4906\n",
      "209.48315\n",
      "209.47575\n",
      "209.46829\n",
      "209.46088\n",
      "209.45341\n",
      "209.44598\n",
      "209.43854\n",
      "209.4311\n",
      "209.42365\n",
      "209.41618\n",
      "209.40872\n",
      "209.40126\n",
      "209.39383\n",
      "209.38632\n",
      "209.37886\n",
      "209.37137\n",
      "209.3639\n",
      "209.35641\n",
      "209.3489\n",
      "209.34145\n",
      "209.33395\n",
      "209.32643\n",
      "209.31894\n",
      "209.31145\n",
      "209.30391\n",
      "209.2964\n",
      "209.28888\n",
      "209.28139\n",
      "209.27385\n",
      "209.26631\n",
      "209.25879\n",
      "209.25125\n",
      "209.2437\n",
      "209.23618\n",
      "209.2286\n",
      "209.2211\n",
      "209.21356\n",
      "209.206\n",
      "209.19841\n",
      "209.19087\n",
      "209.18327\n",
      "209.17572\n",
      "209.16815\n",
      "209.16057\n",
      "209.15302\n",
      "209.14543\n",
      "209.13782\n",
      "209.13023\n",
      "209.12265\n",
      "209.11505\n",
      "209.10745\n",
      "209.09985\n",
      "209.09224\n",
      "209.08464\n",
      "209.07703\n",
      "209.06943\n",
      "209.0618\n",
      "209.05418\n",
      "209.04655\n",
      "209.03894\n",
      "209.03131\n",
      "209.02367\n",
      "209.01602\n",
      "209.00838\n",
      "209.00075\n",
      "208.9931\n",
      "208.98546\n",
      "208.9778\n",
      "208.97017\n",
      "208.96251\n",
      "208.95483\n",
      "208.94717\n",
      "208.93953\n",
      "208.93182\n",
      "208.92415\n",
      "208.9165\n",
      "208.9088\n",
      "208.90115\n",
      "208.89345\n",
      "208.88576\n",
      "208.87807\n",
      "208.8704\n",
      "208.86267\n",
      "208.85498\n",
      "208.84729\n",
      "208.83958\n",
      "208.8319\n",
      "208.82416\n",
      "208.81645\n",
      "208.80873\n",
      "208.80101\n",
      "208.79326\n",
      "208.78558\n",
      "208.77785\n",
      "208.77013\n",
      "208.76239\n",
      "208.75465\n",
      "208.74692\n",
      "208.73918\n",
      "208.73141\n",
      "208.72368\n",
      "208.71593\n",
      "208.70818\n",
      "208.7004\n",
      "208.69266\n",
      "208.68489\n",
      "208.67714\n",
      "208.66939\n",
      "208.6616\n",
      "208.65384\n",
      "208.64606\n",
      "208.6383\n",
      "208.6305\n",
      "208.62273\n",
      "208.61494\n",
      "208.60718\n",
      "208.59938\n",
      "208.59158\n",
      "208.5838\n",
      "208.576\n",
      "208.56824\n",
      "208.5604\n",
      "208.55261\n",
      "208.5448\n",
      "208.53699\n",
      "208.52917\n",
      "208.52136\n",
      "208.5135\n",
      "208.50574\n",
      "208.49788\n",
      "208.49007\n",
      "208.48224\n",
      "208.4744\n",
      "208.46657\n",
      "208.45874\n",
      "208.45088\n",
      "208.44307\n",
      "208.43523\n",
      "208.42737\n",
      "208.41956\n",
      "208.41173\n",
      "208.40384\n",
      "208.396\n",
      "208.38817\n",
      "208.38028\n",
      "208.37242\n",
      "208.36456\n",
      "208.3567\n",
      "208.34883\n",
      "208.34096\n",
      "208.33308\n",
      "208.32523\n",
      "208.3173\n",
      "208.30946\n",
      "208.30156\n",
      "208.29367\n",
      "208.28578\n",
      "208.27794\n",
      "208.27003\n",
      "208.26215\n",
      "208.25423\n",
      "208.24632\n",
      "208.23846\n",
      "208.23053\n",
      "208.22266\n",
      "208.21472\n",
      "208.20683\n",
      "208.1989\n",
      "208.19101\n",
      "208.18309\n",
      "208.17516\n",
      "208.16722\n",
      "208.15932\n",
      "208.15138\n",
      "208.14348\n",
      "208.13554\n",
      "208.12761\n",
      "208.11967\n",
      "208.11176\n",
      "208.10378\n",
      "208.09586\n",
      "208.08792\n",
      "208.07999\n",
      "208.07204\n",
      "208.06409\n",
      "208.05612\n",
      "208.04819\n",
      "208.04025\n",
      "208.03229\n",
      "208.02435\n",
      "208.01637\n",
      "208.00842\n",
      "208.00046\n",
      "207.99248\n",
      "207.98451\n",
      "207.97655\n",
      "207.96857\n",
      "207.96062\n",
      "207.95264\n",
      "207.94467\n",
      "207.93669\n",
      "207.92868\n",
      "207.92072\n",
      "207.9127\n",
      "207.90474\n",
      "207.89674\n",
      "207.88876\n",
      "207.88077\n",
      "207.87274\n",
      "207.86475\n",
      "207.85675\n",
      "207.84875\n",
      "207.84076\n",
      "207.83273\n",
      "207.82472\n",
      "207.81674\n",
      "207.80873\n",
      "207.80072\n",
      "207.7927\n",
      "207.78468\n",
      "207.77666\n",
      "207.76865\n",
      "207.76062\n",
      "207.7526\n",
      "207.74457\n",
      "207.73654\n",
      "207.72853\n",
      "207.72049\n",
      "207.71245\n",
      "207.70442\n",
      "207.69637\n",
      "207.68837\n",
      "207.6803\n",
      "207.67227\n",
      "207.66422\n",
      "207.65617\n",
      "207.64812\n",
      "207.64008\n",
      "207.63203\n",
      "207.62396\n",
      "207.6159\n",
      "207.60785\n",
      "207.59978\n",
      "207.5917\n",
      "207.58368\n",
      "207.57559\n",
      "207.56755\n",
      "207.55948\n",
      "207.5514\n",
      "207.54333\n",
      "207.53525\n",
      "207.52719\n",
      "207.51912\n",
      "207.51103\n",
      "207.50294\n",
      "207.49487\n",
      "207.48683\n",
      "207.47874\n",
      "207.47066\n",
      "207.46252\n",
      "207.45445\n",
      "207.44637\n",
      "207.43826\n",
      "207.43016\n",
      "207.42207\n",
      "207.41394\n",
      "207.40585\n",
      "207.39777\n",
      "207.38966\n",
      "207.38159\n",
      "207.37347\n",
      "207.36534\n",
      "207.35725\n",
      "207.34915\n",
      "207.34103\n",
      "207.33292\n",
      "207.32478\n",
      "207.3167\n",
      "207.30858\n",
      "207.30045\n",
      "207.2923\n",
      "207.2842\n",
      "207.2761\n",
      "207.26793\n",
      "207.2598\n",
      "207.25171\n",
      "207.24355\n",
      "207.23543\n",
      "207.22731\n",
      "207.21916\n",
      "207.21101\n",
      "207.2029\n",
      "207.19475\n",
      "207.18661\n",
      "207.17844\n",
      "207.17029\n",
      "207.16216\n",
      "207.154\n",
      "207.14586\n",
      "207.1377\n",
      "207.1296\n",
      "207.12141\n",
      "207.11324\n",
      "207.1051\n",
      "207.09692\n",
      "207.08876\n",
      "207.0806\n",
      "207.07248\n",
      "207.06429\n",
      "207.05612\n",
      "207.04796\n",
      "207.0398\n",
      "207.0316\n",
      "207.02345\n",
      "207.01529\n",
      "207.00711\n",
      "206.99892\n",
      "206.99075\n",
      "206.98257\n",
      "206.97438\n",
      "206.96622\n",
      "206.958\n",
      "206.94983\n",
      "206.94162\n",
      "206.93346\n",
      "206.9253\n",
      "206.91705\n",
      "206.90887\n",
      "206.90071\n",
      "206.8925\n",
      "206.88431\n",
      "206.87611\n",
      "206.86792\n",
      "206.85971\n",
      "206.8515\n",
      "206.84329\n",
      "206.8351\n",
      "206.8269\n",
      "206.81868\n",
      "206.8105\n",
      "206.80228\n",
      "206.79407\n",
      "206.78589\n",
      "206.77766\n",
      "206.76945\n",
      "206.76118\n",
      "206.753\n",
      "206.74478\n",
      "206.73657\n",
      "206.72833\n",
      "206.72012\n",
      "206.7119\n",
      "206.70367\n",
      "206.69547\n",
      "206.68724\n",
      "206.67896\n",
      "206.67076\n",
      "206.66254\n",
      "206.65428\n",
      "206.64606\n",
      "206.63783\n",
      "206.6296\n",
      "206.62137\n",
      "206.61313\n",
      "206.60487\n",
      "206.59663\n",
      "206.5884\n",
      "206.58012\n",
      "206.57188\n",
      "206.56364\n",
      "206.55539\n",
      "206.54715\n",
      "206.53891\n",
      "206.53065\n",
      "206.52242\n",
      "206.51413\n",
      "206.50589\n",
      "206.49765\n",
      "206.4894\n",
      "206.48114\n",
      "206.47289\n",
      "206.46461\n",
      "206.45636\n",
      "206.44812\n",
      "206.43983\n",
      "206.43153\n",
      "206.42326\n",
      "206.41501\n",
      "206.40675\n",
      "206.39848\n",
      "206.3902\n",
      "206.38194\n",
      "206.37367\n",
      "206.36539\n",
      "206.35707\n",
      "206.34883\n",
      "206.34055\n",
      "206.33226\n",
      "206.324\n",
      "206.3157\n",
      "206.30743\n",
      "206.29913\n",
      "206.2909\n",
      "206.28258\n",
      "206.27428\n",
      "206.26602\n",
      "206.25769\n",
      "206.24944\n",
      "206.24113\n",
      "206.23285\n",
      "206.22453\n",
      "206.21623\n",
      "206.20795\n",
      "206.19965\n",
      "206.19135\n",
      "206.18306\n",
      "206.17476\n",
      "206.16647\n",
      "206.15816\n",
      "206.14987\n",
      "206.14153\n",
      "206.13324\n",
      "206.12492\n",
      "206.11662\n",
      "206.10832\n",
      "206.09999\n",
      "206.0917\n",
      "206.08339\n",
      "206.07506\n",
      "206.06676\n",
      "206.05844\n",
      "206.05011\n",
      "206.0418\n",
      "206.0335\n",
      "206.02516\n",
      "206.01685\n",
      "206.00851\n",
      "206.0002\n",
      "205.99185\n",
      "205.98355\n",
      "205.97523\n",
      "205.96692\n",
      "205.95856\n",
      "205.95024\n",
      "205.94194\n",
      "205.93355\n",
      "205.92523\n",
      "205.91692\n",
      "205.90858\n",
      "205.90027\n",
      "205.89192\n",
      "205.88358\n",
      "205.87526\n",
      "205.86691\n",
      "205.85855\n",
      "205.85019\n",
      "205.84187\n",
      "205.83354\n",
      "205.82518\n",
      "205.81686\n",
      "205.80847\n",
      "205.80016\n",
      "205.7918\n",
      "205.78346\n",
      "205.7751\n",
      "205.76677\n",
      "205.75842\n",
      "205.75008\n",
      "205.7417\n",
      "205.73335\n",
      "205.72499\n",
      "205.71663\n",
      "205.70828\n",
      "205.69992\n",
      "205.69159\n",
      "205.68318\n",
      "205.67484\n",
      "205.6665\n",
      "205.65813\n",
      "205.64977\n",
      "205.64139\n",
      "205.63303\n",
      "205.62465\n",
      "205.61629\n",
      "205.60791\n",
      "205.59956\n",
      "205.59117\n",
      "205.58281\n",
      "205.57443\n",
      "205.56607\n",
      "205.5577\n",
      "205.54933\n",
      "205.54094\n",
      "205.53256\n",
      "205.5242\n",
      "205.51581\n",
      "205.50746\n",
      "205.49902\n",
      "205.49068\n",
      "205.4823\n",
      "205.47394\n",
      "205.46553\n",
      "205.45715\n",
      "205.44876\n",
      "205.44038\n",
      "205.43199\n",
      "205.42361\n",
      "205.41522\n",
      "205.40681\n",
      "205.39844\n",
      "205.39003\n",
      "205.38165\n",
      "205.37328\n",
      "205.36487\n",
      "205.35648\n",
      "205.34808\n",
      "205.3397\n",
      "205.33128\n",
      "205.32289\n",
      "205.31448\n",
      "205.3061\n",
      "205.29771\n",
      "205.28932\n",
      "205.2809\n",
      "205.27249\n",
      "205.26405\n",
      "205.25569\n",
      "205.24728\n",
      "205.23889\n",
      "205.23047\n",
      "205.22206\n",
      "205.21367\n",
      "205.20523\n",
      "205.19682\n",
      "205.18842\n",
      "205.18002\n",
      "205.17162\n",
      "205.16318\n",
      "205.15479\n",
      "205.14636\n",
      "205.13795\n",
      "205.12953\n",
      "205.12111\n",
      "205.11272\n",
      "205.1043\n",
      "205.09586\n",
      "205.08743\n",
      "205.07903\n",
      "205.0706\n",
      "205.06216\n",
      "205.05377\n",
      "205.0453\n",
      "205.0369\n",
      "205.02846\n",
      "205.02007\n",
      "205.01163\n",
      "205.0032\n",
      "204.9948\n",
      "204.98634\n",
      "204.97792\n",
      "204.96948\n",
      "204.96107\n",
      "204.95264\n",
      "204.9442\n",
      "204.93576\n",
      "204.92734\n",
      "204.91888\n",
      "204.91045\n",
      "204.90202\n",
      "204.89355\n",
      "204.88515\n",
      "204.87671\n",
      "204.86827\n",
      "204.85983\n",
      "204.85138\n",
      "204.84293\n",
      "204.83452\n",
      "204.82605\n",
      "204.8176\n",
      "204.8092\n",
      "204.80074\n",
      "204.79227\n",
      "204.78383\n",
      "204.77538\n",
      "204.76694\n",
      "204.7585\n",
      "204.75006\n",
      "204.7416\n",
      "204.73314\n",
      "204.7247\n",
      "204.71623\n",
      "204.7078\n",
      "204.69936\n",
      "204.6909\n",
      "204.68242\n",
      "204.67398\n",
      "204.66551\n",
      "204.65707\n",
      "204.64864\n"
     ]
    }
   ],
   "source": [
    "#create a linear regression using y=mx+b\n",
    "def linear_regression(intercept, slope, features=horsepower):\n",
    "    return slope*features+intercept\n",
    "\n",
    "#create a loss function\n",
    "def loss_function(intercept, slope, target=mpg_1, features=horsepower):\n",
    "    #create predictions\n",
    "    pred=linear_regression(intercept, slope, features)\n",
    "    loss= tf.keras.losses.mse(target, pred)\n",
    "    return loss\n",
    "\n",
    "#create an instance of optimizer\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "#minimize the loss using epochs\n",
    "epochs=1000\n",
    "for i in range(epochs):\n",
    "    opt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "    print(np.array(loss_function(intercept, slope)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create mini batch for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31799173 0.31615734\n"
     ]
    }
   ],
   "source": [
    "#Lets define the intercept and slope of the linear regression\n",
    "intercept=tf.Variable(0.1, np.float32)\n",
    "slope=tf.Variable(0.1, np.float32)\n",
    "#create a linear regression using y=mx+b\n",
    "def linear_regression(intercept, slope, features=size):\n",
    "    return slope*features+intercept\n",
    "\n",
    "#create a loss function\n",
    "def loss_function(intercept, slope, target=price, features=size):\n",
    "    #create predictions\n",
    "    pred=linear_regression(intercept, slope, features)\n",
    "    loss= tf.keras.losses.mse(target, pred)\n",
    "    return loss\n",
    "\n",
    "#create an instance of optimizer\n",
    "opt=tf.keras.optimizers.Adam()\n",
    "\n",
    "#create minibatch from the csv file\n",
    "\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "    price_batch=np.array(batch['price'], np.float32)\n",
    "    size_batch=np.array(batch['sqft_living'], np.float32)\n",
    "    opt.minimize(lambda:loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "print(intercept.numpy(), slope.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layers (Multiple Layer NN)\n",
    "#### Lets Create a simple dense neural network using keras API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take UCI credit card details\n",
    "credit_data=pd.read_csv('uci_credit_card.csv')\n",
    "input=credit_data.drop(['ID','default.payment.next.month'], axis=1)\n",
    "output=credit_data['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 23)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change input as tensorflow constant\n",
    "input_net=tf.constant(input, tf.float32)\n",
    "output_net=tf.constant(output, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define the weights using the normal distribution\n",
    "# Define the layer 1 weights (keep in mind the number of neurons)\n",
    "w1 = tf.Variable(tf.random.normal([23, 10]))\n",
    "# Initialize the layer 1 bias\n",
    "b1 = tf.Variable(tf.ones([10]))\n",
    "# Define the layer 2 weights\n",
    "w2 = tf.Variable(tf.random.normal([10,1]))\n",
    "# Define the layer 2 bias\n",
    "b2 = tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = input_net):\n",
    "\t# Apply relu activation functions to layer 1\n",
    "\tlayer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n",
    "    # Apply dropout rate of 0.25\n",
    "\tdropout = tf.keras.layers.Dropout(0.25)(layer1)\n",
    "\treturn tf.keras.activations.sigmoid(tf.matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = input_net, targets = output_net):\n",
    "\tpredictions = model(w1, b1, w2, b2)\n",
    "\t# Pass targets and predictions to the cross entropy loss\n",
    "\treturn tf.keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), var_list=[w1,b1,w2,b2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 20501.6074 - accuracy: 0.5739 - val_loss: 28.9320 - val_accuracy: 0.9965\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 15.9148 - accuracy: 0.9973 - val_loss: 7.5832 - val_accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.2534 - accuracy: 0.9990 - val_loss: 3.2337 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.4845 - accuracy: 0.9995 - val_loss: 2.9797 - val_accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.9497 - accuracy: 0.9995 - val_loss: 2.7672 - val_accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.9996 - val_loss: 2.7135 - val_accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.5570 - accuracy: 0.9996 - val_loss: 2.6674 - val_accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.9997 - val_loss: 2.5869 - val_accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.9997 - val_loss: 2.5184 - val_accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 0.4150 - accuracy: 0.9997 - val_loss: 2.4304 - val_accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "#create s sequential model\n",
    "model=keras.Sequential()\n",
    "#add first layer\n",
    "model.add(Dense(10,activation='relu', input_shape=(23,)))\n",
    "#add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#compile the model with optimizer and loss\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#fit the model and check the accuracy\n",
    "history=model.fit(input_net, output_net, batch_size=100, epochs=10, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 10)                240       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000001609616FEB0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
